{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MMCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx import *\n",
    "!pip install onnxruntime\n",
    "import onnxruntime\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "#安装onnxrunime\n",
    "wget https://github.com/microsoft/onnxruntime/releases/download/v1.8.1/onnxruntime-linux-x64-1.8.1.tgz\n",
    "tar -zxvf onnxruntime-linux-x64-1.8.1.tgz\n",
    "cd onnxruntime-linux-x64-1.8.1\n",
    "os.environ['ONNXRUNTIME_DIR'] = '/kaggle/working/onnxruntime-linux-x64-1.8.1'\n",
    "export ONNXRUNTIME_DIR=$(pwd)\n",
    "export LD_LIBRARY_PATH=$ONNXRUNTIME_DIR/lib:$LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装MMCV  有强烈的版本匹配问题,/cu110/torch1.7.0必须正确\n",
    "#https://blog.csdn.net/yililjljl/article/details/124896663 查看torchvision,torch,cuda,mmcv版本匹配问题\n",
    "#安装torchvision可以自动更新torch\n",
    "!pip install torchvision==0.8.0  #这个会安装torch==1.7.0\n",
    "#安装对应的mmcv包\n",
    "!pip install mmcv-full==1.5.3 -f https://download.openmmlab.com/mmcv/dist/cu110/torch1.7.0/index.html\n",
    "    \n",
    "# Install mmdetection\n",
    "#rm -rf mmdetection\n",
    "#解决AttributeError: type object ‘Callable‘ has no attribute ‘_abc_registry‘\n",
    "# !pip uninstall typing -y\n",
    "git clone https://github.com/open-mmlab/mmdetection.git\n",
    "cd mmdetection\n",
    "pip install -v -e .\n",
    "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
    "#!pip install Pillow==7.1.0\n",
    "#!pip install tornado==5.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "from mmcv.ops import get_compiling_cuda_version, get_compiler_version\n",
    "print(get_compiling_cuda_version())\n",
    "print(get_compiler_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "子目录或文件 checkpoints 已经存在。\n",
      "'wget' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "#保存路径\n",
    "!mkdir checkpoints\n",
    "#下载checkpoint\n",
    "\n",
    "!wget -c http://download.openmmlab.com/mmdetection/v2.0/yolo/yolov3_d53_320_273e_coco/yolov3_d53_320_273e_coco-421362b6.pth \\\n",
    "      -O checkpoints/tmp.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单的调用执行\n",
    "from mmdet.apis import inference_detector, init_detector, show_result_pyplot\n",
    "\n",
    "# Choose to use a config and initialize the detector\n",
    "config = 'configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = 'checkpoints/tmp.pth'\n",
    "# initialize the detector\n",
    "model = init_detector(config, checkpoint, device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the detector to do inference\n",
    "img = 'demo/demo.jpg'\n",
    "result = inference_detector(model, img)\n",
    "\n",
    "# Let's plot the result\n",
    "show_result_pyplot(model, img, result, score_thr=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     tips:\n",
    "     register中module_dict是个字典，可以用来删除已经注册过的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "temp =os.listdir('/kaggle/input/face-mask-detection/annotations')\n",
    "with open('ann.txt','w') as f:\n",
    "    for item in temp:\n",
    "        strs = item[:-4]\n",
    "        f.write(strs+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义数据集\n",
    "#XML格式的标签数据集制作\n",
    "from mmdet.datasets import XMLDataset\n",
    "import os.path as osp\n",
    "import xml.etree.ElementTree as ET\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "@DATASETS.register_module()\n",
    "class KittiTinyDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = ('Car', 'Pedestrian', 'Cyclist')#所有的类名称\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "    \n",
    "        data_infos = []#完成数据放入列表中，每个样本一个字典\n",
    "        # convert annotations to middle format\n",
    "        for image_id in image_list:\n",
    "            filename = f'{self.img_prefix}/{image_id}.jpeg'\n",
    "            image = mmcv.imread(filename)\n",
    "            height, width = image.shape[:2]\n",
    "    \n",
    "            data_info = dict(filename=f'{image_id}.jpeg', width=width, height=height)\n",
    "    \n",
    "            # load annotations\n",
    "            label_prefix = self.img_prefix.replace('image_2', 'label_2')\n",
    "            lines = mmcv.list_from_file(osp.join(label_prefix, f'{image_id}.txt'))\n",
    "    \n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [[float(info) for info in x[4:8]] for x in content]\n",
    "    \n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "    \n",
    "            # filter 'DontCare'\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                    gt_bboxes.append(bbox)\n",
    "                else:\n",
    "                    gt_labels_ignore.append(-1)\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "\n",
    "            data_anno = dict(\n",
    "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                labels=np.array(gt_labels, dtype=np.long),\n",
    "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
    "                                       dtype=np.float32).reshape(-1, 4),\n",
    "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "\n",
    "        return data_infos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XML格式的标签数据集制作\n",
    "from mmdet.datasets import XMLDataset\n",
    "import os.path as osp\n",
    "import xml.etree.ElementTree as ET\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "@DATASETS.register_module()\n",
    "class FaceMaskDetection(XMLDataset):\n",
    "    \n",
    "    #图片的类别\n",
    "    CLASSES=('mask',)\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__(img_subdir='images',ann_subdir='annotations',**kwargs)\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \"\"\"Load annotation from XML style ann_file.\n",
    "        Args:\n",
    "            ann_file (str): Path of XML file.\n",
    "        Returns:\n",
    "            list[dict]: Annotation info from XML file.\n",
    "        \"\"\"\n",
    "        \n",
    "        data_infos = []\n",
    "        img_ids = mmcv.list_from_file(ann_file)\n",
    "        for img_id in img_ids:\n",
    "            \n",
    "            #修改路径\n",
    "            filename = f'images/{img_id}.jpg'\n",
    "            xml_path = osp.join(self.img_prefix, 'annotations',\n",
    "                                f'{img_id}.xml')\n",
    "            \n",
    "            \n",
    "            tree = ET.parse(xml_path)\n",
    "            root = tree.getroot()\n",
    "            size = root.find('size')\n",
    "            if size is not None:\n",
    "                width = int(size.find('width').text)\n",
    "                height = int(size.find('height').text)\n",
    "            else:\n",
    "                \n",
    "                #图片路径\n",
    "                img_path = osp.join(self.img_prefix, 'images',\n",
    "                                    '{}.jpg'.format(img_id))\n",
    "                \n",
    "                \n",
    "                img = Image.open(img_path)\n",
    "                width, height = img.size\n",
    "            data_infos.append(\n",
    "                dict(id=img_id, filename=filename, width=width, height=height))\n",
    "\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv import Config\n",
    "#模型\n",
    "cfg = Config.fromfile('./configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmdet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a628dcc5f7c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Modify dataset type and path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'KittiTinyDataset'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_root\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'kitti_tiny/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mmdet'"
     ]
    }
   ],
   "source": [
    "from mmdet.apis import set_random_seed\n",
    "# Modify dataset type and path\n",
    "#--------------------------------------data---------------------------------------\n",
    "cfg.type = 'FaceMaskDetection'\n",
    "cfg.data_root = '/kaggle/input/face-mask-detection/'\n",
    "\n",
    "cfg.dataset_type = 'FaceMaskDetection'\n",
    "cfg.data.test.type = 'FaceMaskDetectiont'\n",
    "cfg.data.test.data_root = '/kaggle/input/face-mask-detection/'\n",
    "cfg.data.test.ann_file = '/kaggle/working/mmdetection/ann.txt'\n",
    "cfg.data.test.img_prefix = 'images'\n",
    "cfg.data.test.proposal_file = None\n",
    "\n",
    "cfg.data.train.type = 'FaceMaskDetection'\n",
    "cfg.data.train.data_root = r'/kaggle/input/face-mask-detection/'\n",
    "cfg.data.train.ann_file = '/kaggle/working/mmdetection/ann.txt'\n",
    "cfg.data.train.img_prefix = ''\n",
    "#cfg.data.train.dataset.proposal_file = None\n",
    "\n",
    "cfg.data.val.type = 'FaceMaskDetection'\n",
    "cfg.data.val.data_root = r'/kaggle/input/face-mask-detection/'\n",
    "cfg.data.val.ann_file = '/kaggle/working/mmdetection/ann.txt'\n",
    "cfg.data.val.img_prefix = ''\n",
    "cfg.data.val.proposal_file = None\n",
    "#----------------------------------------------------------------------\n",
    "\n",
    "#----------------------------------model----------------------------------\n",
    "cfg.model.bbox_head.num_classes=2\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.02/16\n",
    "cfg.lr_config.warmup ='linear'\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.evaluation.interval = 12\n",
    "cfg.evaluation.iou_thr=[0.5,0.75,0.95]\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.checkpoint_config.interval = 12\n",
    "\n",
    "\n",
    "cfg.model.pretrained=None\n",
    "#重新训练\n",
    "cfg.load_from =None\n",
    "#继续训练\n",
    "cfg.resume_from=None\n",
    "#在模型内或者在参数外面，以后会修改\n",
    "#cfg.train_cfg=cfg.model.pop('train_cfg')\n",
    "#cfg.test_cfg=cfg.model.pop('test_cfg')\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device='cuda'\n",
    "cfg.workflow=[('train',2),('val',1)]\n",
    "# We can initialize the logger for training and have a look\n",
    "# at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mmdet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7ca080f31381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbuild_detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmmdet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mmdet'"
     ]
    }
   ],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "\n",
    "\n",
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train),build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "#当validation=True的时候才会进行评估\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword argument repeated (<ipython-input-1-5ffb5fc37b41>, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-5ffb5fc37b41>\"\u001b[1;36m, line \u001b[1;32m24\u001b[0m\n\u001b[1;33m    verify=False,\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword argument repeated\n"
     ]
    }
   ],
   "source": [
    "#保存模型\n",
    "torch.save(model.state_dict(),'checkpoint')\n",
    "\n",
    "#模型参数文件\n",
    "modelpath='./configs/yolo/yolov3_d53_320_273e_coco.py'\n",
    "checkpointpath ='checkpoints/tmp.pth'\n",
    "picpath='demo/demo.jpg'\n",
    "model.eval().to('cpu')\n",
    "\n",
    "from mmdetection.tools.deployment.pytorch2onnx import pytorch2onnx\n",
    "input_shape=(1,3,224,224)\n",
    "pytorch2onnx(model, \n",
    "             picpath, \n",
    "             input_shape,\n",
    "             normalize_cfg={'mean':[0.0,0.0,0.0],'std':[0.1,0.1,0.1]},\n",
    "             verify=False,\n",
    "             output_file='tmp.onnx',\n",
    "            skip_postprocess=False,#直接导出模型，不做验证\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcv.parallel import collate, scatter\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmdet.datasets.pipelines import Compose\n",
    "from mmdet.core import get_classes\n",
    "from mmdet.datasets import replace_ImageToTensor\n",
    "\n",
    "#这种形式生成的图片会和模型一致\n",
    "imgs='demo/demo.jpg'\n",
    "imgs = [imgs]\n",
    "cfg = model.cfg #需要模型参数\n",
    "cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "datas = []\n",
    "data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "#要看resize的方式，有缩放因子scale_factor，Pad操作不会影响结果\n",
    "data = test_pipeline(data)\n",
    "datas.append(data)\n",
    "data = collate(datas, samples_per_gpu=len(imgs))\n",
    "data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "data['img'] = [img.data[0] for img in data['img']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    from mmdet.datasets.pipelines import Compose\n",
    "    testpipe = cfg.data.test.pipeline\n",
    "    pipe =Compose(testpipe)\n",
    "    testdata= pipe({'img_info':{'filename':'demo/demo.jpg'},'img_prefix':None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "!pip install onnxruntime\n",
    "import onnxruntime\n",
    "import io\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx\n",
    "from mmdet.core.export.model_wrappers import ONNXRuntimeDetector\n",
    "from mmdet.core.export import build_model_from_cfg, preprocess_example_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入onnx格式的模型\n",
    "output_file='tmp.onnx'\n",
    "onnx_model = onnx.load(output_file)#直接将onnx的图载入\n",
    "#检查一下\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型自带bbox2results函数\n",
    "onnx_model = ONNXRuntimeDetector(output_file, model.CLASSES, 0)\n",
    "\n",
    "#输入大小，\n",
    "input_shape=(1,3,320,320)\n",
    "#路径\n",
    "input_img='demo/demo.jpg'\n",
    "normalize_cfg = {'mean':[123.675, 116.28, 103.53],'std':[58.395, 57.12, 57.375]}\n",
    "\n",
    "input_config = {\n",
    "    'input_shape': input_shape,\n",
    "    'input_path': input_img,\n",
    "    'normalize_cfg': normalize_cfg\n",
    "}\n",
    "#如果是动态输入要修改大小\n",
    "dynamic_export =False\n",
    "if dynamic_export:\n",
    "    # scale up to test dynamic shape\n",
    "    h, w = [int((_ * 1.5) // 32 * 32) for _ in input_shape[2:]]\n",
    "    h, w = min(1344, h), min(1344, w)\n",
    "    input_config['input_shape'] = (1, 3, h, w)\n",
    "    \n",
    "#生成输入,这个是直接使用resize作为输入，使用时需要注意，会影响结果，scale_factor=1\n",
    "one_img, one_meta = preprocess_example_input(input_config)\n",
    "#one_img是直接不管尺度比例，resize到指定大小的图，scale_factor =1\n",
    "img_list, img_meta_list = [one_img], [[one_meta]]\n",
    "\n",
    "\n",
    "# pytorch 输出，可直接用于显示\n",
    "'''\n",
    "with torch.no_grad():\n",
    "\n",
    "    pytorch_results = model(\n",
    "        img_list,\n",
    "        img_metas=img_meta_list,\n",
    "        return_loss=False,\n",
    "        rescale=True)[0]\n",
    "        \n",
    "        '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onnxruntime\n",
    "img_list = [_.cuda().contiguous() for _ in img_list]\n",
    "\n",
    "#自动解码完成\n",
    "onnx_results = onnx_model(\n",
    "    img_list, img_metas=img_meta_list, return_loss=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-005ad817c06d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#可视化onnx的结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshow_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_meta\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'show_img'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mscore_thr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mout_file_ort\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file_pt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m onnx_model.show_result(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_meta' is not defined"
     ]
    }
   ],
   "source": [
    "#可视化onnx的结果\n",
    "show_img = one_meta['show_img']\n",
    "score_thr = 0.3\n",
    "out_file_ort, out_file_pt = None, None\n",
    "#确定是str还是show_img，两个图片大小不一样的\n",
    "onnx_model.show_result(\n",
    "    show_img,\n",
    "    onnx_results,\n",
    "    score_thr=score_thr,\n",
    "    show=True,\n",
    "    win_name='ONNXRuntime',\n",
    "    out_file=out_file_ort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2a25f7857440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#可视化pytorch的结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m model.show_result(\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mshow_img\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpytorch_results\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mscore_thr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscore_thr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#可视化pytorch的结果\n",
    "with torch.no_grad():\n",
    "    model.to('cuda:0')\n",
    "    pytorch_results = model(\n",
    "        img_list,\n",
    "        img_metas=img_meta_list,\n",
    "        return_loss=False,\n",
    "        rescale=True)[0]\n",
    "model.show_result(\n",
    "    show_img,\n",
    "    pytorch_results,\n",
    "    score_thr=score_thr,\n",
    "    show=True,\n",
    "    win_name='PyTorch',\n",
    "    out_file=out_file_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TENSORRT\n",
    "\n",
    "   同onnxruntime是一样的\n",
    "   \n",
    "       !polygraphy surgeon sanitize /kaggle/working/mmdetection/tmp.onnx \\\n",
    "        --fold-constants \\\n",
    "        -o /kaggle/working/folded.onnx\n",
    "        !polygraphy run /kaggle/working/folded.onnx \\\n",
    "        --trt  --onnxrt \\\n",
    "        --input-shapes input:[1,3,416,416] \\\n",
    "        --save-engine temp.plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs='demo/demo.jpg'\n",
    "imgs = [imgs]\n",
    "cfg = model.cfg\n",
    "#需要模型的test对图片进行处理\n",
    "cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)\n",
    "test_pipeline = Compose(cfg.data.test.pipeline)\n",
    "datas = []\n",
    "data = dict(img_info=dict(filename=img), img_prefix=None)\n",
    "data = test_pipeline(data)\n",
    "datas.append(data)\n",
    "data = collate(datas, samples_per_gpu=len(imgs))\n",
    "#img_metas主要保存了scale_factor，将结果变成原图上的结果\n",
    "data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]\n",
    "data['img'] = [img.data[0] for img in data['img']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list, img_meta_list = data['img'], data['img_metas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.core.export.model_wrappers import TensorRTDetector\n",
    "# TensorRTDetector里面有一个engine的装饰器，如果需要自定义模型使用，需要\n",
    "#修改TensorRTDetector 里面forward_test，修改其输入和输出的名字output_names = ['dets', 'labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_model = TensorRTDetector('temp.plane', model.CLASSES, device_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    trt_results = trt_model(\n",
    "        img_list, img_metas=img_meta_list, return_loss=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化结果\n",
    "score_thr = 0.2\n",
    "onnx_model.show_result(\n",
    "    input_img,\n",
    "    trt_results,\n",
    "    score_thr=score_thr,\n",
    "    show=True,\n",
    "    win_name='TensorRT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用OPENVINO进行部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#安装 \n",
    "\n",
    "#Step 3. Set Up and Update PIP to the Highest Version\n",
    "!python -m pip install --upgrade pip\n",
    "\n",
    "#Step 4. Install the Package [caffe,caffe2,onnx,pytorch,tensorflow2]\n",
    "!pip install openvino-dev[onnx]\n",
    "#pip install openvino-dev[tensorflow2,mxnet,caffe]\n",
    "\n",
    "#如果出现缺少libpython3.7m.so.1.0，执行下面的\n",
    "!apt-get install libpython3.7 --yes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "!mo --input_model='tmp.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openvino.runtime import Core\n",
    "import cv2 as cv\n",
    "\n",
    "ie = Core()\n",
    "      \n",
    "model_xml = 'tmp.xml'\n",
    "model_bin = 'tmp.bin'\n",
    "\n",
    "net = ie.read_model(model= model_xml,\n",
    "                      #weights = model_bin\n",
    "                     )\n",
    "compiled_model = ie.compile_model(model=net,device_name=\"CPU\")\n",
    "input_blob = next(iter(net.inputs))\n",
    "#接受输出节点的字典,或者net.outputs是个列表\n",
    "out_blob = next(iter(net.outputs))\n",
    "\n",
    "n,c,h,w = net.inputs[input_blob].shape\n",
    "print(n,c,h,w)\n",
    "\n",
    "src = cv.imread('demo/demo.jpg')\n",
    "image =cv.resize(src,(w,h))\n",
    "#注意数值int8，进行标准化\n",
    "image = np.float32(image)\n",
    "image[:,:,]-= (np.float32(123.675),np.float32(116.28),np.float32(103.53))\n",
    "image[:,:,]/=(np.float32(58.395),np.float32(57.12),np.float32(57.375))\n",
    "\n",
    "input_data = np.expand_dims(np.transpose(image, (2, 0, 1)), 0).astype(np.float32)\n",
    "input_data.shape\n",
    "\n",
    "result = compiled_model([input_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node= []\n",
    "for item in result.keys():\n",
    "    node.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.core import bbox2result\n",
    "#可以将节点转化成列表的形式，再用字典取出\n",
    "dets,labels = result[node[0]],result[node[1]]\n",
    "bbox_results = bbox2result(dets,labels,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_meta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#可视化openvino的结果bbox_results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m show_img \u001b[38;5;241m=\u001b[39m \u001b[43mone_meta\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshow_img\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m score_thr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.4\u001b[39m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mshow_result(\n\u001b[0;32m      5\u001b[0m     show_img,\n\u001b[0;32m      6\u001b[0m     bbox_results,\n\u001b[0;32m      7\u001b[0m     score_thr\u001b[38;5;241m=\u001b[39mscore_thr,\n\u001b[0;32m      8\u001b[0m     show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      9\u001b[0m     win_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENVINO\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_meta' is not defined"
     ]
    }
   ],
   "source": [
    "#可视化openvino的结果bbox_results\n",
    "show_img = one_meta['show_img']\n",
    "score_thr = 0.4\n",
    "model.show_result(\n",
    "    show_img,\n",
    "    bbox_results,\n",
    "    score_thr=score_thr,\n",
    "    show=True,\n",
    "    win_name='OPENVINO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
