{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import sys\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将数据集写入文本中\n",
    "label=os.listdir(train_path)\n",
    "train_path='/kaggle/input/10-monkey-species/training/training/'\n",
    "valid_path='/kaggle/input/10-monkey-species/validation/validation/'\n",
    "with open('train.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(train_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)\n",
    "with open('valid.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(valid_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)#重写数据类，可以将类名加入，也可以不加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算类权重\n",
    "v0=1087\n",
    "v1=2189\n",
    "v2=2386\n",
    "v3=13158\n",
    "v4=2577\n",
    "total=sum([v0,v1,v2,v3,v4])\n",
    "class_weight={0:(1/v0)*(total/5), 1:(1/v1)*(total/5), 2:(1/v2)*(total/5), 3:(1/v3)*(total/5), 4:(1/v4)*(total/5)}\n",
    "class_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据增益方法\n",
    "def augment_list():  # 16 oeprations and their ranges\n",
    "    l = [ (AutoContrast, 0, 1),(Equalize, 0, 1),\n",
    "        (Invert, 0, 1),(Rotate, 0, 30),(Posterize, 0, 4),\n",
    "        (Solarize, 0, 256),(SolarizeAdd, 0, 110),(Contrast, 0.1, 1.9),\n",
    "        (ShearX, 0., 0.3),(ShearY, 0., 0.3),(CutoutAbs, 0, 40),\n",
    "        (TranslateXabs, 0., 100),(TranslateYabs, 0., 100),]\n",
    "    return l\n",
    "class RandAugment:\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m      # [0, 30]\n",
    "        self.augment_list = augment_list()\n",
    "\n",
    "    def __call__(self, img):\n",
    "        ops = random.choices(self.augment_list, k=self.n)\n",
    "        for op, minval, maxval in ops:\n",
    "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
    "            img = op(img, val)\n",
    "        return img\n",
    "    \n",
    "def mixup_data(x,y,alpha=0.9):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "   \n",
    "    batch_size=x.shape[0]\n",
    "\n",
    "    #index = tf.constant(torch.randperm(batch_size))\n",
    "    index=  tf.random.shuffle(tf.range(batch_size))\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * tf.gather(x,index)\n",
    "    y_a, y_b = y,tf.gather(y,index)\n",
    "    return mixed_x, y_a, y_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#制作数据集\n",
    "class Dataset(object):\n",
    "    \n",
    "    CLASSES=None\n",
    "    \n",
    "    def __init__(self, \n",
    "                ann_file,\n",
    "                classes=None,\n",
    "                data_root=None,\n",
    "                test_mode=False,\n",
    "                batch_size=64):\n",
    "        super(Dataset,self).__init__()\n",
    "        \n",
    "        self.ann_file=ann_file\n",
    "        self.batch_size=batch_size\n",
    "        self.test_mode=test_mode\n",
    "\n",
    "        self.data=tf.data.Dataset.from_tensor_slices(self.load_annotations())\n",
    "        # self.data=tf.data.TFRecordDataset('images.tfrecords')\n",
    "        self.data=self.prepare(self.data,mode=self.test_mode)\n",
    "        self.CLASSES = self.get_classes(classes)\n",
    "        \n",
    "    \n",
    "    def load_annotations(self):\n",
    "        #载入所有数据集到列表中\n",
    "        assert isinstance(self.ann_file, str)\n",
    "        data_filename = []\n",
    "        data_label=[]\n",
    "        \n",
    "        #读取txt文件\n",
    "        with open(self.ann_file) as f:\n",
    "            samples = [x.strip().split(' ') for x in f.readlines()]\n",
    "            for filename, gt_label in samples:\n",
    "                data_filename.append(self.data_prefix+filename)\n",
    "                data_label.append(int(gt_label))\n",
    "            return data_filename,data_label\n",
    "        \n",
    "    #如果要用TFrecode格式的文件，需要将解析函数放入类中\n",
    "    def prepare(self,ds,mode):\n",
    "        AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "        ds = ds.map(self._parse_img,num_parallel_calls=AUTOTUNE)#简单的解析出图片\n",
    "   \n",
    "        if not mode:\n",
    "            # num_parallel_calls=tf.data.AUTOTUNE 并行\n",
    "            #cache可以缓存一些打开过的文件\n",
    "            ds = ds.shuffle(1000).map(self._augment_func,\n",
    "                        num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "        else:\n",
    "            ds = ds.map(self._valid_func,\n",
    "                       num_parallel_calls=tf.data.experimental.AUTOTUNE).cache()\n",
    "        ds = ds.batch(self.batch_size)\n",
    "        return ds.prefetch(buffer_size=AUTOTUNE)#训练的时候也读取数据\n",
    "    \n",
    "    def _parse_img(self,filename,label):\n",
    "\n",
    "        file=tf.io.read_file(filename)\n",
    "        img_raw=tf.image.decode_jpeg(file)\n",
    "        \n",
    "        return img_raw,label\n",
    "        \n",
    "    @tf.function\n",
    "    def _augment_func(self,img,label):\n",
    "        #以图的方式进行，更加快\n",
    "        img = tf.image.resize(img, [256, 256])\n",
    "        #batch_num=tf.shape(img)[0]\n",
    "        #[batch_num,224,224,3]如果已经切batch了，就要把第一个维度加上去\n",
    "        img = tf.image.random_crop(img,[224,224,3])\n",
    " \n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        return img,label\n",
    "    \n",
    "    \n",
    "    @tf.function\n",
    "    def _valid_func(self,img,label):\n",
    "        \n",
    "        img = tf.image.resize(img, [256, 256])/255.0\n",
    "        img=tf.image.resize_with_crop_or_pad(img,224,224)\n",
    "        return img,label    \n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def get_classes(cls, classes=None):\n",
    "        if classes is None:\n",
    "            return cls.CLASSES\n",
    "\n",
    "        if isinstance(classes, (tuple, list)):\n",
    "            class_names = classes\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported type {type(classes)} of classes.')\n",
    "\n",
    "        return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=Dataset('/kaggle/working/train.txt',\n",
    "                  '/kaggle/input/10-monkey-species/training/training/'\n",
    "                 ,batch_size=128)\n",
    "validdata=Dataset('/kaggle/working/valid.txt',\n",
    "                  '/kaggle/input/10-monkey-species/validation/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU\n",
    "stragy=tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "epochs=20\n",
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        x,y = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True)  # Forward pass\n",
    "            #y_pred=self(mixed_x,training=True)\n",
    "            # Compute the loss value\n",
    "            # (the loss function is configured in `compile()`)\n",
    "            \n",
    "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with stragy.scope():\n",
    "    \n",
    "    model=resnet50.ResNet50(weights='imagenet')\n",
    "    feature=keras.Model(model.input,model.layers[-3].output)\n",
    "    inputs=layers.Input(shape=(224,224,3))\n",
    "    x=feature(inputs)\n",
    "    x=layers.GlobalAvgPool2D()(x)\n",
    "    x=layers.Dropout(0.5)(x)\n",
    "    outputs=layers.Dense(10)(x)\n",
    "\n",
    "    mymodel=MyModel(inputs,outputs)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule=tf.keras.optimizers.schedules.ExponentialDecay(0.01,decay_steps=10000,decay_rate=0.96)\n",
    "\n",
    "\n",
    "mymodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    optimizer='adam',\n",
    "           #optimizer=tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True),\n",
    "                    run_eagerly=True)\n",
    "\n",
    "history=mymodel.fit(traindata.data,epochs=epochs,class_weight=class_weight)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord文件生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following functions can be used to convert a value to a type compatible\n",
    "# with tf.Example.\n",
    "\n",
    "def _bytes_feature(value):\n",
    "        \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "\n",
    "#这个是不管输入是标量还是列表，统一用列表处理\n",
    "def int64_feature(value):\n",
    "    \"\"\"Wrapper for inserting int64 features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def float_feature(value):\n",
    "    \"\"\"Wrapper for inserting float features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def bytes_feature(value):\n",
    "    \"\"\"Wrapper for inserting bytes features into Example proto.\n",
    "    \"\"\"\n",
    "    if not isinstance(value, list):\n",
    "        value = [value]\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_image(name,\n",
    "                   img_path='/kaggle/input/coco128/coco128/images/train2017/',\n",
    "                   ann_path='/kaggle/input/coco128/coco128/labels/train2017/'):\n",
    "    # Read the image file.\n",
    "    filename = img_path +name\n",
    "    image_data = tf.io.read_file(filename)\n",
    "\n",
    "    \n",
    "    \n",
    "    # Read the XML annotation file.\n",
    "    filename = os.path.join(ann_path,name.split('.')[0]+'.txt')\n",
    "    with open(filename,'r') as f:\n",
    "        labels = []\n",
    "        bboxes = []\n",
    "        for line in f.readlines():\n",
    "            \n",
    "            line=line.strip().split()\n",
    "            label = int(line[0])\n",
    "            x1,y1,x2,y2 = float(line[1]), float(line[2]), float(line[3]), float(line[4])\n",
    "            labels.append(label)\n",
    "            bboxes.append((x1,y1,x2,y2))\n",
    "    return image_data,labels,bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_to_example(image_data,labels,bboxes):\n",
    "    xmin = []\n",
    "    ymin = []\n",
    "    xmax = []\n",
    "    ymax = []\n",
    "    for b in bboxes:\n",
    "        assert len(b) == 4\n",
    "        # pylint: disable=expression-not-assigned\n",
    "        [l.append(point) for l, point in zip([ymin, xmin, ymax, xmax], b)]\n",
    "        # pylint: enable=expression-not-assigned\n",
    "\n",
    "    image_format = b'JPEG'\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            #'image/height': int64_feature(shape[0]),\n",
    "            #'image/width': int64_feature(shape[1]),\n",
    "            #'image/channels': int64_feature(shape[2]),\n",
    "            #'image/shape': int64_feature(shape),\n",
    "            'image/object/bbox/xmin': float_feature(xmin),\n",
    "            'image/object/bbox/xmax': float_feature(xmax),\n",
    "            'image/object/bbox/ymin': float_feature(ymin),\n",
    "            'image/object/bbox/ymax': float_feature(ymax),\n",
    "            'image/object/bbox/label': int64_feature(labels),\n",
    "            #'image/object/bbox/label_text': bytes_feature(labels_text),\n",
    "            #'image/object/bbox/difficult': int64_feature(difficult),\n",
    "            #'image/object/bbox/truncated': int64_feature(truncated),\n",
    "            #'image/format': bytes_feature(image_format),\n",
    "            'image/encoded': _bytes_feature(image_data)#这是个张量字符串\n",
    "            }))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_to_tfrecord(name, tfrecord_writer):\n",
    "\n",
    "    image_data,labels , bboxes= _process_image(name)\n",
    "    example = _convert_to_example(image_data, labels, bboxes)\n",
    "    tfrecord_writer.write(example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_output_filename(output_dir, name, idx):\n",
    "    return '%s/%s_%03d.tfrecord' % (output_dir, name, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(dataset_dir, output_dir, name='train', shuffling=False):\n",
    "\n",
    "    filenames = sorted(os.listdir(dataset_dir))\n",
    "    if shuffling:\n",
    "        random.seed(RANDOM_SEED)\n",
    "        random.shuffle(filenames)\n",
    "\n",
    "    # Process dataset files.\n",
    "    i = 0\n",
    "    fidx = 0\n",
    "    while i < len(filenames):\n",
    "        # Open new TFRecord file.\n",
    "        tf_filename = _get_output_filename(output_dir, name, fidx)\n",
    "   \n",
    "        with tf.io.TFRecordWriter(tf_filename) as tfrecord_writer:\n",
    "            j = 0\n",
    "            while i < len(filenames) and j < 20:\n",
    "                sys.stdout.write('\\r>> Converting image %d/%d' % (i+1, len(filenames)))\n",
    "                sys.stdout.flush()\n",
    "                filename = filenames[i]\n",
    "                \n",
    "                _add_to_tfrecord(filename, tfrecord_writer)\n",
    "                i += 1\n",
    "                j += 1\n",
    "            fidx += 1\n",
    "\n",
    "    # Finally, write the labels file:\n",
    "    # labels_to_class_names = dict(zip(range(len(_CLASS_NAMES)), _CLASS_NAMES))\n",
    "    # dataset_utils.write_label_file(labels_to_class_names, dataset_dir)\n",
    "    print('\\nFinished converting the Pascal VOC dataset!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('/kaggle/input/coco128/coco128/images/train2017/','/kaggle/working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Example 消息（或 protobuf）是一种灵活的消息类型，表示 {\"string\": value} 映射。它专为 TensorFlow 而设计，并被用于 TFX 等高级 API。\n",
    "\n",
    "#要处理非标量特征，最简单的方法是使用 tf.io.serialize_tensor 将张量转换为二进制字符串。\n",
    "#在 TensorFlow 中，字符串是标量。使用 tf.io.parse_tensor 可将二进制字符串转换回张量。\n",
    "\n",
    "#反向转化为Example\n",
    "#example_proto = tf.train.Example.FromString(serialized_example)\n",
    "\n",
    "\n",
    "#读取\n",
    "raw_image_dataset = tf.data.TFRecordDataset(filename)\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "        'image/object/bbox/xmin': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymin': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/xmax': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/ymax': tf.io.VarLenFeature(dtype=tf.float32),\n",
    "        'image/object/bbox/label': tf.io.VarLenFeature(dtype=tf.int64),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#显示图片的方式，TENSORFLOW读入的是二进制图片\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "for image_features in parsed_image_dataset.take(1):\n",
    "    image_raw = image_features['image/encoded'].numpy()\n",
    "    #print(image_raw)\n",
    "    p_img = Image.open(BytesIO(image_raw)) #这样可以保证图片是PIL的\n",
    "    plt.imshow(p_img)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 增益图片\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将增益的compose pipeline 写成层的形式\n",
    "IMG_SIZE = 180\n",
    "\n",
    "resize_and_rescale = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n",
    "  layers.experimental.preprocessing.Rescaling(1./255)\n",
    "])\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "  layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
    "  layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "#还是用map函数进行增益吧\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_img(d):\n",
    "    img = d['image/encoded']\n",
    "    img= tf.image.decode_jpeg(img)\n",
    "    img = tf.image.adjust_brightness(img, 0.4)\n",
    "    d['image/encoded'] =img\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 73)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<tokenize>\"\u001b[1;36m, line \u001b[1;32m73\u001b[0m\n\u001b[1;33m    return tf.io.parse_single_example(example_proto, image_feature_description)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "##构造类，调用时什么都不用给\n",
    "class Dataset(object):\n",
    "    def __init__(self,\n",
    "                tf_path=None,\n",
    "                mode='train',\n",
    "                batch_size=10):\n",
    "        super(Dataset,self).__init__()\n",
    "        \n",
    "        self.batch_size=batch_size\n",
    "        self.mode=mode\n",
    "        #指定tf文件的名称即可\n",
    "        self.data=tf.data.TFRecordDataset(tf_path)\n",
    "        \n",
    "        self.data=self.prepare(self.data,mode=self.mode)\n",
    "        \n",
    "    def prepare(self,ds,mode):\n",
    "        AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "        ds = ds.map(self._parse_image_function)\n",
    "        ds = ds.map(self._parse_img,num_parallel_calls=AUTOTUNE)#简单的解析出图片\n",
    "   \n",
    "        if mode=='train':\n",
    "            ds = ds.shuffle(1000).map(self._augment_func,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        else:\n",
    "            ds = ds.map(self._valid_func,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.batch(self.batch_size)\n",
    "        return ds.prefetch(buffer_size=AUTOTUNE)\n",
    "    \n",
    "    def _parse_img(self,items):\n",
    "        img_raw = tf.image.decode_jpeg(items['image/encoded'])\n",
    "        items['image/encoded'] = img_raw\n",
    "        return items\n",
    "    \n",
    "    def _parse_image_function(self,example_proto):\n",
    "      # Parse the input tf.Example proto using the dictionary above.\n",
    "      return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    \n",
    "    @tf.function\n",
    "    def _augment_func(self,items):#不能修改，可以复制\n",
    "        new_item = items.copy()\n",
    "        img = tf.image.resize(items['image/encoded'], [256, 256])\n",
    "\n",
    "        img = tf.image.random_crop(img,[224,224,3])\n",
    " \n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        new_item['image/encoded'] =img\n",
    "        return new_item\n",
    "    \n",
    "    @tf.function\n",
    "    def _valid_func(self,img,label):\n",
    "        img = tf.image.resize(img, [256, 256])/255.0\n",
    "        img=tf.image.resize_with_crop_or_pad(img,224,224)\n",
    "        return img,label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mixed_precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b9b0ded7bafc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#混合精度使用方法\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#创建dtype策略，这个是全局的设置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mixed_float16'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmixed_precision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Compute dtype: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mixed_precision' is not defined"
     ]
    }
   ],
   "source": [
    "#混合精度使用方法\n",
    "#创建dtype策略，这个是全局的设置\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "#自定义模型，每一层都是用到全局设置的值\n",
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "dense2 = layers.Dense(num_units, activation='relu', name='dense_2')\n",
    "x = dense2(x)\n",
    "\n",
    "#为了保证稳定性，需要对模型最后一层用float32的设置，dtype='float32'，不一定是激活层\n",
    "outputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "print('Outputs dtype: %s' % outputs.dtype.name)\n",
    "\n",
    "\n",
    "#将输入数据从 int8 强制转换为 float32\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "#自定义训练\n",
    "#这种计算需要考虑下溢的问题，损失放大就是一个防止出现下溢的技巧\n",
    "loss_scale = policy.loss_scale\n",
    "print('Loss scale: %s' % loss_scale)\n",
    "#先设置优化器\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')\n",
    "\n",
    "#修改自定义训练方式\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(x):\n",
    "    return model(x, training=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FP16的高效计算\n",
    "!git clone https://github.com/NVIDIA/apex\n",
    "%cd apex\n",
    "!python setup.py install\n",
    "\n",
    "#混合精度使用方法\n",
    "#创建dtype策略，这个是全局的设置\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)\n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)\n",
    "\n",
    "#自定义模型，每一层都是用到全局设置的值\n",
    "inputs = keras.Input(shape=(784,), name='digits')\n",
    "dense2 = layers.Dense(num_units, activation='relu', name='dense_2')\n",
    "x = dense2(x)\n",
    "\n",
    "#为了保证稳定性，需要对模型最后一层用float32的设置，dtype='float32'，不一定是激活层\n",
    "outputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)\n",
    "print('Outputs dtype: %s' % outputs.dtype.name)\n",
    "\n",
    "\n",
    "#将输入数据从 int8 强制转换为 float32\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "#自定义训练\n",
    "#这种计算需要考虑下溢的问题，损失放大就是一个防止出现下溢的技巧\n",
    "loss_scale = policy.loss_scale\n",
    "print('Loss scale: %s' % loss_scale)\n",
    "#先设置优化器\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "optimizer = mixed_precision.LossScaleOptimizer(optimizer, loss_scale='dynamic')\n",
    "\n",
    "#修改自定义训练方式\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    gradients = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "def test_step(x):\n",
    "    return model(x, training=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
