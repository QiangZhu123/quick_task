{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openmim\n",
    "!mim install mmcv\n",
    "!git clone https://github.com/open-mmlab/mmclassification.git\n",
    "%cd mmclassification\n",
    "!pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "from mmcls.datasets.builder import DATASETS\n",
    "from mmcls.datasets import BaseDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from mmcls.apis import train_model,inference_model,show_result_pyplot,set_random_seed\n",
    "from mmcls.datasets import build_dataset,build_dataloader\n",
    "from mmcls.models import build_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据路径\n",
    "training_data_path='/kaggle/input/10-monkey-species/training/training/'\n",
    "valid_data_path='/kaggle/input/10-monkey-species/validation/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='RandomResizedCrop',\n",
    "        size=224,\n",
    "        backend='pillow',\n",
    "        interpolation='bicubic'),\n",
    "    dict(type='RandomFlip', flip_prob=0.5, direction='horizontal'),\n",
    "    dict(\n",
    "        type='RandAugment',\n",
    "        policies=_base_.rand_increasing_policies,\n",
    "        num_policies=2,\n",
    "        total_level=10,\n",
    "        magnitude_level=9,\n",
    "        magnitude_std=0.5,\n",
    "        hparams=dict(\n",
    "            pad_val=[round(x) for x in img_norm_cfg['mean'][::-1]],\n",
    "            interpolation='bicubic')),\n",
    "    dict(type='RandomErasing',\n",
    "        erase_prob=0.25,\n",
    "        mode='rand',\n",
    "        min_area_ratio=0.02,\n",
    "        max_area_ratio=1 / 3,\n",
    "        fill_color=img_norm_cfg['mean'][::-1],\n",
    "        fill_std=img_norm_cfg['std'][::-1]),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='ToTensor', keys=['gt_label']),\n",
    "    dict(type='Collect', keys=['img', 'gt_label'])\n",
    "]\n",
    "\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        size=(256, -1),\n",
    "        backend='pillow',\n",
    "        interpolation='bicubic'),\n",
    "    dict(type='CenterCrop', crop_size=224),\n",
    "    dict(type='Normalize', **img_norm_cfg),\n",
    "    dict(type='ImageToTensor', keys=['img']),\n",
    "    dict(type='Collect', keys=['img'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取所有的参数,参数文件就在当下文件夹中\n",
    "cfg = Config.fromfile('./configs/resnext/resnext50_32x4d_b32x8_imagenet.py')\n",
    "print(f'Config:\\n{cfg.pretty_text}')  #输出所有的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.model.head.num_classes = 10 \n",
    "\n",
    "cfg.dataset_type = 'CustomDataset'\n",
    "cfg.data.train.type = 'CustomDataset'\n",
    "cfg.data.train.data_prefix = training_data_path\n",
    "cfg.data.train.pipeline = train_pipeline\n",
    "\n",
    "cfg.data.val.type ='CustomDataset'\n",
    "cfg.data.val.data_prefix = valid_data_path\n",
    "cfg.data.val.ann_file =None\n",
    "cfg.data.val.pipeline[-1]=dict(type='Collect', keys=['img'])\n",
    "\n",
    "cfg.data.test.type ='CustomDataset'\n",
    "cfg.data.test.data_prefix = valid_data_path\n",
    "cfg.data.test.ann_file =None\n",
    "cfg.data.test.pipeline = test_pipeline\n",
    "cfg.data.test.pipeline[-1]=dict(type='Collect', keys=['img','gt_label'])\n",
    "\n",
    "# Modify the evaluation metric\n",
    "cfg.evaluation['metric_options']={'topk': (1, )}\n",
    "\n",
    "#cfg.load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'   #是否是预训练模型\n",
    "cfg.init_cfg = dict(type='TruncNormal', layer='Linear', mean=0.2)\n",
    "\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer =dict(type='AdamW',lr=0.004,weight_decay=0.05,)\n",
    "\n",
    "#学习率调整  参数一定要传对\n",
    "#cfg.lr_config = dict(policy='step', step=[30, 60, 90])\n",
    "#cfg.lr_config = dict(policy='exp',gamma=0.1)\n",
    "#cfg.lr_config = dict(policy='fixed')\n",
    "#cfg.lr_config = dict(policy='poly',power=1.25, min_lr=0.001)\n",
    "cfg.lr_config=dict(policy='CosineAnnealing',min_lr=0.0001)\n",
    "#cfg.lr_config = dict(policy='CosineRestart',periods=[1,3])\n",
    " \n",
    "cfg.lr_config.warmup='linear'\n",
    "cfg.lr_config.warmup_iters=20\n",
    "cfg.lr_config.warmup_ratio=0.001\n",
    "\n",
    "cfg.runner = dict(type='EpochBasedRunner', max_epochs=100) #训练迭代次数\n",
    "\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "\n",
    "cfg.evaluation.interval = 12\n",
    "cfg.checkpoint_config.interval = 12\n",
    "cfg.work_dir = './tutorial_exps'\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)#设备指定\n",
    "cfg.device='cuda'\n",
    "#val是runer中的val_step，执行和train_step一样，计算损失的，并不是训练集评估acc\n",
    "cfg.workflow= [('train', 2),('val',1)]\n",
    "#print(f'Config:\\n{cfg.pretty_text}')  #输出所有的参数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#构造数据集，它的长度len(data_loaders) == len(workflow)\n",
    "datasets = [build_dataset(cfg.data.train),build_dataset(cfg.data.test)]\n",
    "#workflow 中的评估数据集是计算loss的，所以必须在pipeline中给定label\n",
    "#datasets = [build_dataset(cfg.data.train),build_dataset(cfg.data.val)]\n",
    "# Build the detector\n",
    "model = build_classifier(cfg.model) #建立模型\n",
    "\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES#将类名加入到模型中\n",
    "\n",
    "# Create work_dir\n",
    "#如果要在val数据上测试，则要validata=True，而不是设置work_flow\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))#创建保存文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, \n",
    "            datasets, \n",
    "            cfg, \n",
    "            distributed=False,\n",
    "            validate=True) #validate=True 是在val数据集上做评估的，pipeline中不能有label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP16训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.fp16 = dict(loss_scale='dynamic')\n",
    "#执行训练过程\n",
    "cfg.optimizer_config = dict(grad_clip=None)\n",
    "#必须给一个meta{}\n",
    "train_model(model, \n",
    "            datasets, \n",
    "            cfg, \n",
    "            distributed=False,\n",
    "            validate=False,\n",
    "            meta ={}) #训练validate=True是用来做eval的钩子的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmcls.apis import inference_model\n",
    "model.eval()\n",
    "model.cfg=cfg\n",
    "#model.cfg.data.test.pipeline[-1]={'type': 'Collect', 'keys': ['img']}\n",
    "result = inference_model(model, '/kaggle/input/10-monkey-species/training/training/n0/n0018.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单机多卡命令行实现训练\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只能用 tools/train.py进行分布式训练，缺少init_函数\n",
    "                         #1 config                             #GPU \n",
    "!bash dist_train.sh ../configs/resnet/resnet18_8xb16_cifar10.py 2 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
