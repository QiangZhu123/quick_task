{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入文件名\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "#from skimage.io import imread\n",
    "from PIL import Image\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50,resnet18\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.cuda.is_available()\n",
    "device=torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定路径,只要给保存的路径即可\n",
    "training_data_path='/kaggle/input/10-monkey-species/training/training/'\n",
    "valid_data_path='/kaggle/input/10-monkey-species/validation/validation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写成文本文件\n",
    "label=os.listdir(training_data_path)\n",
    "label.sort()\n",
    "with open('train.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(training_data_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)\n",
    "with open('valid.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(valid_data_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)#重写数据类，可以将类名加入，也可以不加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_root='/kaggle/input/garbage-classification'\n",
    "class Monkey(Dataset):\n",
    "    CLASSES={'n0': 0, 'n1': 1,'n2': 2,'n3': 3, 'n4': 4,'n5': 5,'n6': 6,'n7': 7, 'n8': 8,'n9': 9}\n",
    "    def __init__(self,data_root,ann_file,pipeline=None,classes=None):\n",
    "        #数据名列表\n",
    "        super().__init__()\n",
    "        self.data_infos=[]\n",
    "        self.labels=[]\n",
    "        self.data_root=data_root\n",
    "        self.pipeline=Compose(pipeline)\n",
    "        #用到文本文件\n",
    "        f=open(ann_file,'r')\n",
    "        for line in f:\n",
    "            filename,label=line.strip().split(' ')\n",
    "            item = {'file':filename,'label':label}\n",
    "            self.data_infos.append(item)\n",
    "        self._len=len(self.data_infos)\n",
    "    def __getitem__(self,index):\n",
    "        info=self.data_infos[index]\n",
    "        img_path=os.path.join(self.data_root,info['file'])\n",
    "        img=Image.open(img_path)\n",
    "        if self.pipeline:\n",
    "            img=self.pipeline(img)     \n",
    "        return img,int(info['label'])\n",
    "    def __len__(self):\n",
    "        return self._len  \n",
    "#或者直接调用简单的分类数据集函数\n",
    "mean = [110.508858, 109.552668,84.623747]\n",
    "std = [67.212821,66.229520, 66.544232]\n",
    "\n",
    "#训练集，使用ImageFolder可以更快速的构建分类数据集。数据集的分布只要按要求写好，再给定路径和增益方法即可\n",
    "traindata=Monkey('/kaggle/input/10-monkey-species/training/training/',\n",
    "              '/kaggle/working/train.txt',pipeline=[transforms.Resize(256),\n",
    "      transforms.RandomCrop(224), transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),transforms.Normalize(mean=mean,std=std)])#增益方法\n",
    "trainloader= torch.utils.data.DataLoader(traindata, shuffle=True,\n",
    "           num_workers=2,batch_size=64,pin_memory=True)\n",
    "#验证集\n",
    "validdata=Monkey('/kaggle/input/10-monkey-species/validation/validation/',\n",
    "              '/kaggle/working/valid.txt',pipeline=[transforms.Resize((224,224),),\n",
    "         transforms.ToTensor(),transforms.Normalize(mean=mean,std=std) ])\n",
    "validloader=torch.utils.data.DataLoader(validdata,batch_size=64,shuffle=False)\n",
    "'''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义增益函数\n",
    "class Mytransform:\n",
    "    \n",
    "    '''\n",
    "    这个差不多要消耗2s/128\n",
    "    '''\n",
    "    def __init__(self,shot_size):\n",
    "        super().__init__()\n",
    "        self.short = shot_size\n",
    "    def __call__(self,data):\n",
    "        h , w = np.array(data).shape[:2]\n",
    "        s = min ( h , w )\n",
    "        if s == h:\n",
    "            scale = h/self.short\n",
    "            h = self.short\n",
    "            w = int(w/scale)\n",
    "        else:\n",
    "            scale = w/self.short\n",
    "            w = self.short\n",
    "            h = int(h/scale)\n",
    "        #选择插值模式\n",
    "        data = transforms.Resize((h,w))(data)\n",
    "        return data  #data就是一张图\n",
    "\n",
    "Augment=Compose([\n",
    "        Mytransform(256),\n",
    "        transforms.RandomCrop(224),#这里之前都是对PIL图片处理，mixup在train里做\n",
    "        transforms.ToTensor(),#有归一化到【0，1】的作用，并且交换通道\n",
    "        transforms.Normalize(mean=mean,std=std),\n",
    "                ])  #进行数据增益的方法\n",
    "\n",
    "\n",
    "#训练集，使用ImageFolder可以更快速的构建分类数据集。数据集的分布只要按要求写好，再给定路径和增益方法即可\n",
    "traindata=ImageFolder(training_data_path,#数据集路径\n",
    "                      transform=Augment)#增益方法\n",
    "trainloader= torch.utils.data.DataLoader(traindata,\n",
    "                                shuffle=True,\n",
    "                                num_workers=4,\n",
    "                                batch_size=64,\n",
    "                                pin_memory=True)\n",
    "#验证集\n",
    "validdata=ImageFolder(valid_data_path,transform=Compose([transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(224),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean = mean,std = std),]))\n",
    "validloader=torch.utils.data.DataLoader(validdata,\n",
    "                                        shuffle=False,\n",
    "                                       batch_size=64,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 保证输入大小不变，常用\n",
    "torch.backends.cudnn.benchmark=True \n",
    "\n",
    "#预训练模型,nn.Conv2d中 bias=False \n",
    "model = resnet18(pretrained=True) \n",
    "num_ftrs = model.fc.in_features \n",
    "model.fc = torch.nn.Linear(num_ftrs, 10) #修改分类头\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练设置\n",
    "#损失函数\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#优化器和学习率调整\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "#exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# 超级加速\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.001,weight_decay=1e-4, amsgrad=False)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-8-e7cd90eb8294>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-e7cd90eb8294>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    epoch_loss= 0.0\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "epochs= 30 \n",
    "for epoch in range(epochs):\n",
    "    epoch_loss= 0.0\n",
    "    epoch_count = 0\n",
    "    model.train()\n",
    "    print(f'Epoch {epoch}/{epochs}')\n",
    "    print('----------------------------')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i,(img,label) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        img=img.to(device)\n",
    "        label = label.to(device)\n",
    "        prediction = model(img)\n",
    "        _ , correct = torch.max(prediction,dim=1)\n",
    "        loss = criterion(prediction,label)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_count += (correct==label).sum().item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        exp_lr_scheduler.step()\n",
    "    \n",
    "    one_epoch_time = time.time()-start_time\n",
    "    \n",
    "    if (epoch+1) % 3 == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        eval_loss=0.0\n",
    "        eval_accuracy=0.0\n",
    "            \n",
    "        for image,label in validloader:\n",
    "                \n",
    "            image=image.to(device)\n",
    "            label=label.to(device)\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                pred=model(image)\n",
    "                \n",
    "            loss = criterion(pred,label)\n",
    "            _ , count = torch.max(pred,dim=1)\n",
    "            \n",
    "            eval_accuracy += (count==label).sum().item()\n",
    "            eval_loss += loss.item()\n",
    "        print (f'valid Loss: {eval_loss:.4f} Acc:{eval_accuracy /len(validdata):.4f}')\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "    print (f'one_epoch_time :{one_epoch_time:.4f},lr : {optimizer.param_groups[0][\"lr\"]},train Loss: {epoch_loss:.4f} Acc:{epoch_count/len(traindata):.4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#或者是\n",
    "import time\n",
    "dataset_sizes={'train':traindata,'val':validdata}\n",
    "dataloaders={'train':trainloader,'val':validloader}\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / len(dataset_sizes[phase])\n",
    "            epoch_acc = running_corrects.double() / len(dataset_sizes[phase])\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "model= train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存模型\n",
    "torch.save(model.state_dict(),'mymodel.pth')\n",
    "#或者\n",
    "torch.save(model,'allmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/apex\n",
    "%cd apex\n",
    "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apex import amp\n",
    "#只要三行代码就可以\n",
    "\n",
    "# Added after model and optimizer construction\n",
    "model, optimizer = amp.initialize(model, optimizer, flags...)\n",
    "...\n",
    "# loss.backward() changed to:\n",
    "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "    scaled_loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "#O0：纯FP32训练，可以作为accuracy的baseline；\n",
    "#O1：混合精度训练（推荐使用），根据黑白名单自动决定使用FP16（GEMM, 卷积）还是FP32（Softmax）进行计算。\n",
    "#O2：“几乎FP16”混合精度训练，不存在黑白名单，除了Batch norm，几乎都是用FP16计算。\n",
    "#O3：纯FP16训练，很不稳定，但是可以作为speed的baseline；\n",
    "\n",
    "opt_level = 'O1'\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "\n",
    "# Train your model\n",
    "...\n",
    "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "    scaled_loss.backward()\n",
    "...\n",
    "\n",
    "# Save checkpoint\n",
    "checkpoint = {\n",
    "    'model': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'amp': amp.state_dict()\n",
    "}\n",
    "torch.save(checkpoint, 'amp_checkpoint.pt')\n",
    "...\n",
    "\n",
    "# Restore\n",
    "model = ...\n",
    "optimizer = ...\n",
    "checkpoint = torch.load('amp_checkpoint.pt')\n",
    "\n",
    "model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "amp.load_state_dict(checkpoint['amp'])\n",
    "\n",
    "# Continue training\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 或者使用torch.cuda.amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# amp依赖Tensor core架构，所以model参数必须是cuda tensor类型\n",
    "model = Net().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), ...)\n",
    "# GradScaler对象用来自动做梯度缩放\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in epochs:\n",
    "    for input, target in data:\n",
    "        optimizer.zero_grad()\n",
    "        # 在autocast enable 区域运行forward\n",
    "        with autocast():\n",
    "            # model做一个FP16的副本，forward\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "        # 用scaler，scale loss(FP16)，backward得到scaled的梯度(FP16)\n",
    "        scaler.scale(loss).backward()\n",
    "        # scaler 更新参数，会先自动unscale梯度\n",
    "        # 如果有nan或inf，自动跳过\n",
    "        scaler.step(optimizer)\n",
    "        # scaler factor更新\n",
    "        scaler.update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
