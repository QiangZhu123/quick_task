{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DALI\n",
    "import torch, torchvision\n",
    "import copy\n",
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "from torchvision import models\n",
    "\n",
    "#安装\n",
    "!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-cuda110\n",
    "#!pip install --extra-index-url https://developer.download.nvidia.com/compute/redist nvidia-dali-tf-plugin-cuda110\n",
    "\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "#DALIClassificationIterator(pipelines, reader_name)  ==  DALIGenericIterator(pipelines, [\"data\", \"label\"], reader_name)\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy#（这个是用于填充作用）\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "\n",
    "#自定义增益函数\n",
    "#from dali_augment import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path='/kaggle/input/10-monkey-species/monkey_labels.txt'\n",
    "root='/kaggle/input/10-monkey-species/'\n",
    "training_data_path='/kaggle/input/10-monkey-species/training/training/'\n",
    "valid_data_path='/kaggle/input/10-monkey-species/validation/validation/'\n",
    "means=[110.508858,109.552668, 84.623747]\n",
    "stds=[67.212821,66.229520,66.544232]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写成文本文件\n",
    "label=os.listdir(training_data_path)\n",
    "with open('train.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(training_data_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)\n",
    "with open('valid.txt','w') as f:\n",
    "    for l in range(len(label)):\n",
    "        for filename in os.listdir(os.path.join(valid_data_path,label[l])):\n",
    "            line=f'{label[l]}/{filename} {l}\\n'\n",
    "            f.write(line)#重写数据类，可以将类名加入，也可以不加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自己定义数据来源"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandAugment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f32818beccb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrandom\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0maug\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandAugment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;31m#和下面是一样的，这个是自定义数据源fn.external_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m def ExternalSourcePipeline(batch_size,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandAugment' is not defined"
     ]
    }
   ],
   "source": [
    "#构造自己的数据集类\n",
    "from random import shuffle\n",
    "#数据源生成器\n",
    "class ExternalInputIterator(object):\n",
    "    def __init__(self, batch_size, \n",
    "                 device_id,\n",
    "                 num_gpus,\n",
    "                ann_file=\"/kaggle/working/train.txt\",\n",
    "                img_prex='/kaggle/input/10-monkey-species/training/training/'):\n",
    "        self.ann_file =ann_file\n",
    "        self.batch_size = batch_size\n",
    "        self.img_prex=img_prex\n",
    "        #读取txt文本\n",
    "        with open(self.ann_file, 'r') as f:\n",
    "            self.files = [line.rstrip() for line in f if line is not '']\n",
    "        self.data_set_len = len(self.files)\n",
    "        self.files = self.files[self.data_set_len * device_id // num_gpus:self.data_set_len * (device_id + 1) //num_gpus]\n",
    "        self.n = len(self.files)\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        shuffle(self.files)\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "        if self.i >= self.n:\n",
    "            raise StopIteration\n",
    "        #生成一个batch的数据\n",
    "        for _ in range(self.batch_size):\n",
    "            #处理字符串\n",
    "            jpeg_filename, label = self.files[self.i].split(' ')\n",
    "            # we can use numpy\n",
    "            batch.append(np.fromfile(self.img_prex+jpeg_filename, dtype = np.uint8)) \n",
    "            # or PyTorch's native tensors\n",
    "            labels.append(torch.tensor([int(label)], dtype = torch.uint8)) \n",
    "            self.i = (self.i + 1) % self.n\n",
    "            \n",
    "            '''\n",
    "            #GPU版本\n",
    "                import cupy as cp\n",
    "                import imageio\n",
    "            GPU版本的，但是依然是在CPU上处理，只是处理的结果放到了GPU上面\n",
    "            jpeg_filename, label = self.files[self.i].split(' ')\n",
    "            im = imageio.imread(self.img_prex + jpeg_filename)\n",
    "            im = cp.asarray(im)\n",
    "            im = im * 0.6;\n",
    "            batch.append(im.astype(cp.uint8))\n",
    "            labels.append(cp.array([label], dtype = np.uint8))\n",
    "            '''\n",
    "            \n",
    "        return (batch, labels)#这里就说明了他是dataloader格式的结果\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_set_len\n",
    "\n",
    "#生成pipeline\n",
    "def ExternalSourcePipeline(batch_size, \n",
    "                           num_threads, \n",
    "                           device_id, \n",
    "                           external_data,\n",
    "                          is_training=True,\n",
    "                          dali_cpu=False):\n",
    "    pipe = Pipeline(batch_size, num_threads,device_id)\n",
    "\n",
    "    with pipe:\n",
    "        #用np.fromfile 读取成一列数据\n",
    "        jpegs, labels = fn.external_source(source=external_data, \n",
    "                                           num_outputs=2)#输出个数保证一致\n",
    "        \n",
    "        \n",
    "        #设置设备\n",
    "        dali_device = 'cpu' if dali_cpu else 'gpu'\n",
    "        decoder_device = 'cpu' if dali_cpu else 'mixed'\n",
    "        device_memory_padding = 211025920 if decoder_device == 'mixed' else 0\n",
    "        host_memory_padding = 140544512 if decoder_device == 'mixed' else 0\n",
    "        \n",
    "        \n",
    "        if is_training:\n",
    "            #增益方法\n",
    "            images = fn.decoders.image_random_crop(jpegs,\n",
    "                                                  device=decoder_device,\n",
    "                                                   output_type=types.RGB,\n",
    "                                                  device_memory_padding=device_memory_padding,\n",
    "                                                  host_memory_padding=host_memory_padding,\n",
    "                                                  random_aspect_ratio=[0.8, 1.25],\n",
    "                                                  random_area=[0.1, 1.0]\n",
    "                                                  ,num_attempts=100)\n",
    "            \n",
    "            \n",
    "            #images =augment(images)\n",
    "            images = fn.resize(images, resize_x=240, resize_y=240)\n",
    "            mirror = fn.random.coin_flip(probability=0.5)\n",
    "        else:\n",
    "            images = fn.decoders.image(jpegs,\n",
    "                                      device='mixed',\n",
    "                                      output_type=types.RGB)\n",
    "            images = fn.resize(images, resize_x=240, resize_y=240)\n",
    "            mirror = False\n",
    "        images = fn.crop_mirror_normalize(images.gpu(),\n",
    "                                          dtype=types.FLOAT,\n",
    "                                          output_layout=\"CHW\",\n",
    "                                          mean=[0.485 * 255,0.456 * 255,0.406 * 255],\n",
    "                                          std=[0.229 * 255,0.224 * 255,0.225 * 255],\n",
    "                                          mirror=mirror)\n",
    "        labels = labels.gpu()\n",
    "        pipe.set_outputs(images, labels)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "#实例化训练数据的来源，生成器\n",
    "train_eii = ExternalInputIterator(256, 0, 1)\n",
    "\n",
    "#构造训练pipe\n",
    "train_pipe = ExternalSourcePipeline(batch_size=256, \n",
    "                              num_threads=2,\n",
    "                              device_id = 0,\n",
    "                              external_data = train_eii,\n",
    "                               dali_cpu=False)\n",
    "\n",
    "train_pipe.build()\n",
    "trainloader= DALIGenericIterator(train_pipe,\n",
    "                          [\"images\",\"labels\"],\n",
    "                           size=len(train_eii),\n",
    "                          auto_reset=True,\n",
    "                          last_batch_policy=LastBatchPolicy.PARTIAL)#其他任务要调用这个\n",
    "\n",
    "\n",
    "#实例化验证数据的来源\n",
    "valids_eii = ExternalInputIterator(64, 0, 1, \n",
    "                ann_file=\"/kaggle/working/valid.txt\",\n",
    "                img_prex='/kaggle/input/10-monkey-species/validation/validation/')\n",
    "#再构造验证pipe\n",
    "valid_pipe = ExternalSourcePipeline(batch_size=64, \n",
    "                              num_threads=2,\n",
    "                              device_id = 0,\n",
    "                              external_data = valids_eii,\n",
    "                              is_training=False,\n",
    "                              dali_cpu=False)\n",
    "valid_pipe.build()\n",
    "#pii = PyTorchIterator(pipe, size=len(eii), last_batch_padded=True, last_batch_policy=LastBatchPolicy.PARTIAL)\n",
    "validloader= DALIGenericIterator(valid_pipe,\n",
    "                          [\"images\",\"labels\"],\n",
    "                           size=len(valids_eii),\n",
    "                          last_batch_policy=LastBatchPolicy.PARTIAL)#其他任务要调用这个"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用内置的读取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#和上面是一样的, 区别是没有写生成数据，而是直接调用fn.file_reader，并且整合了InputIterator和PIPELINE两步操作\n",
    "\n",
    "def create_dali_pipeline(batch_size, \n",
    "                         num_threads,\n",
    "                         device_id, \n",
    "                         data_dir, \n",
    "                         crop,\n",
    "                         size,\n",
    "                         shard_id, \n",
    "                         num_shards,\n",
    "                         dali_cpu=False, \n",
    "                         is_training=True):\n",
    "    pipeline = Pipeline(batch_size, \n",
    "                        num_threads, \n",
    "                        device_id, seed=12 + device_id)\n",
    "    with pipeline:\n",
    "        images, labels = fn.readers.file(file_root=data_dir,\n",
    "                                        shard_id=0,\n",
    "                                        num_shards=1,\n",
    "                                        random_shuffle=is_training,\n",
    "                                        pad_last_batch=True,name=\"Reader\")\n",
    "        #指定设备\n",
    "        dali_device = 'cpu' if dali_cpu else 'gpu'\n",
    "        decoder_device = 'cpu' if dali_cpu else 'mixed'\n",
    "        device_memory_padding = 211025920 if decoder_device == 'mixed' else 0\n",
    "        host_memory_padding = 140544512 if decoder_device == 'mixed' else 0\n",
    "        \n",
    "        if is_training:\n",
    "            #这个是解码函数，是在mixed上执行\n",
    "            images = fn.decoders.image_random_crop(images,\n",
    "                                                  device=decoder_device,\n",
    "                                                   output_type=types.RGB,\n",
    "                                                  device_memory_padding=device_memory_padding,\n",
    "                                                  host_memory_padding=host_memory_padding,\n",
    "                                                  random_aspect_ratio=[0.8, 1.25],\n",
    "                                                  random_area=[0.1, 1.0]\n",
    "                                                  ,num_attempts=100)\n",
    "            #之后要在GPU上执行\n",
    "            images = fn.resize(images,\n",
    "                               device=dali_device,\n",
    "                               resize_x=crop,\n",
    "                               resize_y=crop,\n",
    "                               interp_type=types.INTERP_TRIANGULAR)\n",
    "            mirror = fn.random.coin_flip(probability=0.5)\n",
    "        else:\n",
    "            images = fn.decoders.image(images,\n",
    "                                      device=decoder_device,\n",
    "                                      output_type=types.RGB)\n",
    "            images = fn.resize(images,\n",
    "                               device=dali_device,\n",
    "                               size=size,\n",
    "                               mode=\"not_smaller\",\n",
    "                               interp_type=types.INTERP_TRIANGULAR)\n",
    "            mirror = False\n",
    "            \n",
    "        #这个很关键，执行的TOTENSOR和NORMIZATION两个操作\n",
    "        images = fn.crop_mirror_normalize(images.gpu(),\n",
    "                                          dtype=types.FLOAT,\n",
    "                                          output_layout=\"CHW\",\n",
    "                                          crop=(crop, crop),\n",
    "                                          mean=[0.485 * 255,0.456 * 255,0.406 * 255],\n",
    "                                          std=[0.229 * 255,0.224 * 255,0.225 * 255],\n",
    "                                          mirror=mirror)\n",
    "        labels = labels.gpu()\n",
    "        pipeline.set_outputs(images, labels)\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dali_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0e0a261c69f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mval_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m pipe = create_dali_pipeline(batch_size=128,num_threads=1,device_id=0,data_dir=training_data_path,\n\u001b[0m\u001b[0;32m      5\u001b[0m                             \u001b[0mcrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdali_cpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshard_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                            is_training=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dali_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#常规的分类数据集使用这个\n",
    "crop_size=224\n",
    "val_size=224\n",
    "\n",
    "pipe = create_dali_pipeline(batch_size=128,\n",
    "                            num_threads=1,\n",
    "                            device_id=0,\n",
    "                            data_dir=training_data_path,\n",
    "                            crop=crop_size,\n",
    "                            size=val_size,\n",
    "                            dali_cpu=False,\n",
    "                            shard_id=0,\n",
    "                            num_shards=1,\n",
    "                           is_training=True)\n",
    "pipe.build()\n",
    "trainloader = DALIClassificationIterator(pipe, \n",
    "                                         reader_name=\"Reader\", \n",
    "                                         last_batch_policy=LastBatchPolicy.PARTIAL)#这是一个生成器\n",
    "pipe = create_dali_pipeline(batch_size=64,\n",
    "                            num_threads=1,\n",
    "                            device_id=0,\n",
    "                            data_dir=valid_data_path,\n",
    "                            crop=crop_size,\n",
    "                            size=val_size,\n",
    "                            dali_cpu=False,\n",
    "                            shard_id=0,\n",
    "                            num_shards=1,\n",
    "                           is_training=False)\n",
    "pipe.build()\n",
    "validloader = DALIClassificationIterator(pipe, \n",
    "                                         reader_name=\"Reader\",\n",
    "                                         last_batch_policy=LastBatchPolicy.PARTIAL)#这是一个生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f038d56cb52c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda:0\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m \u001b[1;31m# 保证输入大小不变\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#预训练模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_ftrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_ftrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#修改分类头\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#调用模型\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark=True # 保证输入大小不变\n",
    "model = models.resnet18(pretrained=True) #预训练模型\n",
    "num_ftrs = model.fc.in_features \n",
    "model.fc = torch.nn.Linear(num_ftrs, 10) #修改分类头\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-57c8394bdff4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Observe that all parameters are being optimized  优化器\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStepLR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#训练设置\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized  优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs 超级加速\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=0.001,weight_decay=1e-4, amsgrad=False)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4c44728fb9d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mepoch_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mepoch_num\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch}/{epochs}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#训练过程\n",
    "epochs= 30 \n",
    "for epoch in range(epochs):\n",
    "    epoch_loss= 0.0\n",
    "    epoch_count = 0\n",
    "    model.train()\n",
    "    print(f'Epoch {epoch}/{epochs}')\n",
    "    print('----------------------------')\n",
    "    start_time = time.time()\n",
    "    for i,data in enumerate(trainloader):\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        img = data[0][\"images\"]#注意标签\n",
    "        label = data[0][\"labels\"].squeeze(-1).cuda().long()\n",
    "        \n",
    "        #已经在GPU上了\n",
    "        #img=img.to(device)\n",
    "        #label = label.to(device)\n",
    "        \n",
    "        prediction = model(img)\n",
    "        _ , correct = torch.max(prediction,dim=1)\n",
    "        loss = criterion (prediction,label)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_count +=  (correct==label).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        exp_lr_scheduler.step()\n",
    "        one_epoch_time = time.time()-start_time\n",
    "    print (f'one_epoch_time :{one_epoch_time:.4f},lr : {optimizer.param_groups[0][\"lr\"]},train Loss: {epoch_loss:.4f} Acc:{epoch_count/len(trainloader)/256*100:.4f} ')\n",
    "    if (epoch+1) % 3 == 0:\n",
    "        model.eval()\n",
    "        eval_loss=0.0\n",
    "        eval_accuracy=0.0\n",
    "            \n",
    "        for data in validloader:\n",
    "            \n",
    "            image = data[0][\"images\"]\n",
    "            label = data[0][\"labels\"].squeeze(-1).cuda().long()\n",
    "            \n",
    "            #数据已经在GPU上了\n",
    "            #image=image.to(device)\n",
    "            #label=label.to(device)\n",
    "                \n",
    "            with torch.no_grad():\n",
    "                pred=model(image)\n",
    "            loss = criterion (pred,label)\n",
    "            _ , count = torch.max(pred,dim=1)\n",
    "            eval_accuracy += (count==label).sum().item()\n",
    "            eval_loss += loss.item()\n",
    "        print (f'valid Loss: {eval_loss:.4f} Acc:{eval_accuracy /len(validloader)/64*100:.4f}')\n",
    "        \n",
    "        model.train()\n",
    "    \n",
    "    \n",
    "    trainloader.reset()\n",
    "    validloader.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FP16训练 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# amp依赖Tensor core架构，所以model参数必须是cuda tensor类型\n",
    "model = Net().cuda()\n",
    "optimizer = optim.SGD(model.parameters(), ...)\n",
    "# GradScaler对象用来自动做梯度缩放\n",
    "scaler = GradScaler()\n",
    "\n",
    "for epoch in epochs:\n",
    "    for input, target in data:\n",
    "        optimizer.zero_grad()\n",
    "        # 在autocast enable 区域运行forward\n",
    "        with autocast():\n",
    "            # model做一个FP16的副本，forward\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output, target)\n",
    "        # 用scaler，scale loss(FP16)，backward得到scaled的梯度(FP16)\n",
    "        scaler.scale(loss).backward()\n",
    "        # scaler 更新参数，会先自动unscale梯度\n",
    "        # 如果有nan或inf，自动跳过\n",
    "        scaler.step(optimizer)\n",
    "        # scaler factor更新\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定位 \n",
    "画矩形\n",
    "import matplotlib.patches as patches\n",
    "rect = patches.Rectangle((l, t), width=(r - l), height=(b - t),linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "ax.add_patch(rect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline_def' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f837da6cd1ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mpipeline_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_coco_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mshard_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mnum_shards\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_world_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline_def' is not defined"
     ]
    }
   ],
   "source": [
    "@pipeline_def\n",
    "def create_coco_pipeline(default_boxes, args):\n",
    "    try:\n",
    "        shard_id = torch.distributed.get_rank()\n",
    "        num_shards = torch.distributed.get_world_size()\n",
    "    except RuntimeError:\n",
    "        shard_id = 0\n",
    "        num_shards = 1\n",
    "    #读取方式\n",
    "    inputs, bboxes, labels, polygons, vertices = fn.readers.coco(\n",
    "        file_root=file_root,\n",
    "        annotations_file=annotations_file,\n",
    "        polygon_masks=True, # Load segmentation mask data as polygons\n",
    "        ratio=True,         # Bounding box and mask polygons to be expressed in relative coordinates\n",
    "        ltrb=True,          # Bounding boxes to be expressed as left, top, right, bottom coordinates\n",
    "    )\n",
    "    images, bboxes, labels = fn.readers.coco(file_root=args.train_coco_root,\n",
    "                                             annotations_file=args.train_annotate,\n",
    "                                             skip_empty=True,\n",
    "                                             shard_id=shard_id,\n",
    "                                             num_shards=num_shards,\n",
    "                                             ratio=True,\n",
    "                                             ltrb=True,\n",
    "                                             random_shuffle=False,\n",
    "                                             shuffle_after_epoch=True,\n",
    "                                             name=\"Reader\")\n",
    "    #只处理bboxes\n",
    "    crop_begin, crop_size, bboxes, labels = fn.random_bbox_crop(bboxes, labels,\n",
    "                                                                device=\"cpu\",\n",
    "                                                                aspect_ratio=[0.5, 2.0],\n",
    "                                                                thresholds=[0, 0.1, 0.3, 0.5, 0.7, 0.9],#裁剪的IOU\n",
    "                                                                scaling=[0.3, 1.0],\n",
    "          bbox_layout=\"xyXY\",#[start_x, start_y, end_x, and end_y],对应的还有”xyWH”=[start_x,start_y,width,height]\n",
    "                                                                allow_no_crop=True,\n",
    "                                                                num_attempts=50)                #尝试次数\n",
    "    #用上面的结果给image_slice方法使用来处理图片的裁剪\n",
    "    images = fn.decoders.image_slice(images, crop_begin, crop_size, device=\"mixed\", output_type=types.RGB)\n",
    "    flip_coin = fn.random.coin_flip(probability=0.5)\n",
    "    images = fn.resize(images,\n",
    "                       resize_x=300,\n",
    "                       resize_y=300,\n",
    "                       min_filter=types.DALIInterpType.INTERP_TRIANGULAR)\n",
    "    \n",
    "    #生成随机数\n",
    "    saturation = fn.uniform(range=[0.5, 1.5])\n",
    "    contrast = fn.uniform(range=[0.5, 1.5])\n",
    "    brightness = fn.uniform(range=[0.875, 1.125])\n",
    "    hue = fn.uniform(range=[-0.5, 0.5])\n",
    "    \n",
    "    #调节图片色度\n",
    "    images = fn.hsv(images, dtype=types.FLOAT, hue=hue, saturation=saturation)  # use float to avoid clipping and\n",
    "                                                         # quantizing the intermediate result\n",
    "    images = fn.brightness_contrast(images,\n",
    "                                    contrast_center = 128,  # input is in float, but in 0..255 range\n",
    "                                    dtype = types.UINT8,\n",
    "                                    brightness = brightness,\n",
    "                                    contrast = contrast)\n",
    "\n",
    "    dtype = types.FLOAT16 if args.fp16 else types.FLOAT\n",
    "    \n",
    "    #图片翻转\n",
    "    bboxes = fn.bb_flip(bboxes, ltrb=True, horizontal=flip_coin)\n",
    "    images = fn.crop_mirror_normalize(images,\n",
    "                                      crop=(300, 300),\n",
    "                                      mean=[0.485 * 255, 0.456 * 255, 0.406 * 255],\n",
    "                                      std=[0.229 * 255, 0.224 * 255, 0.225 * 255],\n",
    "                                      mirror=flip_coin,\n",
    "                                      dtype=dtype,\n",
    "                                      output_layout=\"CHW\",\n",
    "                                      pad_output=False)\n",
    "    #编码\n",
    "    bboxes, labels = fn.box_encoder(bboxes, labels,\n",
    "                                    criteria=0.5,\n",
    "                                    anchors=default_boxes.as_ltrb_list())#这个是进行bboxes编码工作的，直接给定anchor来计算bboxes\n",
    "\n",
    "    labels=labels.gpu()\n",
    "    bboxes=bboxes.gpu()\n",
    "\n",
    "    return images, bboxes, labels\n",
    "\n",
    "\n",
    "\n",
    "train_pipe = create_coco_pipeline(\n",
    "    default_boxes,\n",
    "    args,\n",
    "    batch_size=args.batch_size,\n",
    "    num_threads=args.num_workers,\n",
    "    device_id=args.local_rank,\n",
    "    seed=local_seed)\n",
    "\n",
    "#定位使用的类\n",
    "train_loader = DALIGenericIterator(\n",
    "    train_pipe,\n",
    "    [\"images\", \"boxes\", \"labels\"],\n",
    "    reader_name=\"Reader\",\n",
    "    last_batch_policy=LastBatchPolicy.FILL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#通用过程就是先创建一个Pipeline实例,在实例里完成整个管道构建\n",
    "#pipe.build()\n",
    "#pipe.run()\n",
    "\n",
    "pipe = Pipeline(batch_size=batch_size, num_threads=num_threads, device_id=device_id, seed=11)\n",
    "with pipe:\n",
    "    # COCO reader, with piwelwise masks\n",
    "    inputs, bboxes, labels, masks = fn.readers.coco(\n",
    "        file_root=file_root,\n",
    "        annotations_file=annotations_file,\n",
    "        pixelwise_masks=True # Load segmentation pixelwise mask data\n",
    "    )\n",
    "    #解码图片\n",
    "    images = fn.decoders.image(inputs)\n",
    "\n",
    "    # COCO reader produces three dimensions (H, W, 1). Here we are just removing the trailing dimension\n",
    "    # rel_shape=(1, 1) means keep the first two dimensions as they are.\n",
    "    masks = fn.reshape(masks, rel_shape=(1, 1))\n",
    "\n",
    "    # Select random foreground pixels with 70% probability and random pixels with 30% probability\n",
    "    # Foreground pixels are by default those with value higher than 0.\n",
    "    center = fn.segmentation.random_mask_pixel(\n",
    "        masks, foreground=fn.random.coin_flip(probability=0.7)\n",
    "    )\n",
    "\n",
    "    # Random crop shape (can also be constant)\n",
    "    crop_h = fn.cast(fn.random.uniform(range=(200, 300), shape=(1,), device='cpu'), dtype=types.INT64)\n",
    "    crop_w = fn.cast(fn.random.uniform(range=(200, 300), shape=(1,), device='cpu'), dtype=types.INT64)\n",
    "    crop_shape = fn.cat(crop_h, crop_w, axis=0)\n",
    "\n",
    "    # Calculating anchor for slice (top-left corner of the cropping window)\n",
    "    crop_anchor = center - crop_shape // 2\n",
    "\n",
    "    # Slicing image and mask.\n",
    "    # Note that we are allowing padding when sampling out of bounds, since a foreground pixel can appear\n",
    "    # near the edge of the image.\n",
    "    out_image = fn.slice(images, crop_anchor, crop_shape, axis_names=\"HW\", out_of_bounds_policy='pad')\n",
    "    out_mask = fn.slice(masks, crop_anchor, crop_shape, axis_names=\"HW\", out_of_bounds_policy='pad')\n",
    "    \n",
    "    #这是最后一步,完成建立pipeline\n",
    "    pipe.set_outputs(images, masks, center, crop_anchor, crop_shape, out_image, out_mask)\n",
    "    \n",
    "pipe.build()\n",
    "outputs = pipe.run()\n",
    "i = 16\n",
    "image = outputs[0].at(i)\n",
    "mask = outputs[1].at(i)\n",
    "center = outputs[2].at(i)\n",
    "anchor = outputs[3].at(i)\n",
    "shape = outputs[4].at(i)\n",
    "out_image = outputs[5].at(i)\n",
    "out_mask = outputs[6].at(i)\n",
    "\n",
    "\n",
    "#可视化\n",
    "fig, ax = plt.subplots(dpi=160)\n",
    "ax.imshow(image)\n",
    "ax.imshow(mask, cmap='jet', alpha=0.5)\n",
    "rect = patches.Rectangle((anchor[1], anchor[0]), width=shape[1], height=shape[0],\n",
    "                         linewidth=1, edgecolor='#76b900', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "ax.scatter(center[1], center[0], s=10, edgecolor='#76b900')\n",
    "plt.title('Original Image/Mask with random crop window and center')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(dpi=160)\n",
    "ax.imshow(out_image)\n",
    "ax.imshow(out_mask, cmap='jet', alpha=0.5)\n",
    "plt.title('Cropped Image/Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试管道\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "from nvidia.dali import pipeline_def\n",
    "%matplotlib inline\n",
    "\n",
    "def show_images(image_batch):\n",
    "    columns = 4\n",
    "    rows = (16 + 1) // (columns)\n",
    "    fig = plt.figure(figsize = (32,(32 // columns) * rows))\n",
    "    gs = gridspec.GridSpec(rows, columns)\n",
    "    for j in range(rows*columns):\n",
    "        plt.subplot(gs[j])\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(image_batch.at(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ExternalInputIterator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-a9f9e35f62df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meii\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mExternalInputIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     images, labels = fn.external_source(source=eii,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ExternalInputIterator' is not defined"
     ]
    }
   ],
   "source": [
    "#定义管道的方法\n",
    "#  并行化参数(batch_size=batch_size, num_threads=2, device_id=0, py_num_workers=4, py_start_method='spawn')\n",
    "@pipeline_def\n",
    "def random_rotated_gpu_pipeline():\n",
    "    #读取图片\n",
    "    jpegs, labels = fn.readers.file(file_root=training_data_path, \n",
    "                                    random_shuffle=True, #在这里shuffle\n",
    "                                    initial_fill=21,\n",
    "                                   #parallel=True,并行化\n",
    "                                   )\n",
    "    images = fn.decoders.image(jpegs, device='mixed')\n",
    "    angle = fn.random.uniform(range=(-10.0, 10.0))\n",
    "    rotated_images = fn.rotate(images.gpu(), #这里是将图片放到GPU上\n",
    "                               angle=angle, \n",
    "                               fill_value=0)\n",
    "\n",
    "    return rotated_images, labels,angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = random_rotated_gpu_pipeline(batch_size=16, num_threads=4, device_id=0)\n",
    "pipe.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_out = pipe.run()\n",
    "print(pipe_out)\n",
    "images, labels,angle = pipe_out\n",
    "#要把图片复制CPU上才能可视化，并不能从GPU移动到CPU上\n",
    "show_images(images.as_cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dfdc4555f5ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 序列化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#反序列化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpipe2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_threads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# 序列化\n",
    "s = pipe.serialize()\n",
    "#反序列化\n",
    "pipe2 = Pipeline(batch_size = batch_size, num_threads = 2, device_id = 0, seed = 12)\n",
    "\n",
    "pipe2.deserialize_and_build(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意事项\n",
    "\n",
    "*Since decoders.image does not accept data on the GPU we need to decode it outside DALI on the CPU and then move it to the GPU.\n",
    "\n",
    "*data[0].at(5)只能用at方法来切片\n",
    "\n",
    "*data[0].as_cpu().at(5)顺序不能改\n",
    "\n",
    "*as_array()是一个关键函数\n",
    "\n",
    "*angle = fn.random.uniform(range=(-10.0, 10.0)) #生成随机数,是增益的重要函数\n",
    "        saturation = fn.uniform(range=[0.5, 1.5])\n",
    "        contrast = fn.uniform(range=[0.5, 1.5])\n",
    "        brightness = fn.uniform(range=[0.875, 1.125])\n",
    "        hue = fn.uniform(range=[-0.5, 0.5])\n",
    "\n",
    "*nvidia.dali.fn 包中有所有的处理函数Operations\n",
    "\n",
    "*nvidia.dali.math 支持的数学计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义计算OP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建一个OP头文件\n",
    "#!cat customdummy/dummy.h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #ifndef EXAMPLE_DUMMY_H_\n",
    "    #define EXAMPLE_DUMMY_H_\n",
    "\n",
    "    #include <vector>\n",
    "\n",
    "    #include \"dali/pipeline/operator/operator.h\"\n",
    "\n",
    "    namespace other_ns {\n",
    "\n",
    "    template <typename Backend>\n",
    "    class Dummy : public ::dali::Operator<Backend> {\n",
    "     public:\n",
    "      inline explicit Dummy(const ::dali::OpSpec &spec) :\n",
    "        ::dali::Operator<Backend>(spec) {}\n",
    "\n",
    "      virtual inline ~Dummy() = default;\n",
    "\n",
    "      Dummy(const Dummy&) = delete;\n",
    "      Dummy& operator=(const Dummy&) = delete;\n",
    "      Dummy(Dummy&&) = delete;\n",
    "      Dummy& operator=(Dummy&&) = delete;\n",
    "\n",
    "     protected:\n",
    "     \n",
    "      //是否有输出信息推断，就是setupimpl的指示\n",
    "      bool CanInferOutputs() const override {\n",
    "        return true;\n",
    "      }\n",
    "      \n",
    "      \n",
    "      //根据输入来计算输出的形状和类型\n",
    "      bool SetupImpl(std::vector<::dali::OutputDesc> &output_desc,\n",
    "                     const ::dali::workspace_t<Backend> &ws) override {\n",
    "        const auto &input = ws.template InputRef<Backend>(0);\n",
    "        output_desc.resize(1);\n",
    "        output_desc[0] = {input.shape(), input.type()};\n",
    "        return true;\n",
    "      }\n",
    "       \n",
    "      //主执行函数，在.CC文件中实现\n",
    "      void RunImpl(::dali::workspace_t<Backend> &ws) override;\n",
    "    };\n",
    "\n",
    "    }  // namespace other_ns\n",
    "\n",
    "    #endif  // EXAMPLE_DUMMY_H_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPU上的实现\n",
    "#!cat customdummy/dummy.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    //头文件导入\n",
    "    #include \"dummy.h\"\n",
    "\n",
    "    namespace other_ns {\n",
    "\n",
    "\n",
    "    //OP实现的方法具体执行，输入是整个batch\n",
    "    template <>\n",
    "    void Dummy<::dali::CPUBackend>::RunImpl(::dali::HostWorkspace &ws) {\n",
    "      const auto &input = ws.InputRef<::dali::CPUBackend>(0);\n",
    "      auto &output = ws.OutputRef<::dali::CPUBackend>(0);\n",
    "\n",
    "      ::dali::TypeInfo type = input.type();\n",
    "      auto &tp = ws.GetThreadPool();\n",
    "      const auto &in_shape = input.shape();\n",
    "      for (int sample_id = 0; sample_id < in_shape.num_samples(); sample_id++) {\n",
    "        tp.AddWork(\n",
    "            [&, sample_id](int thread_id) {\n",
    "              type.Copy<::dali::CPUBackend, ::dali::CPUBackend>(output.raw_mutable_tensor(sample_id),\n",
    "                                                                input.raw_tensor(sample_id),\n",
    "                                                                in_shape.tensor_size(sample_id), 0);\n",
    "            },\n",
    "            in_shape.tensor_size(sample_id));\n",
    "      }\n",
    "      tp.RunAll();\n",
    "    }\n",
    "\n",
    "    }  // namespace other_ns\n",
    "    \n",
    "    \n",
    "    //注册接口，注意修改名称\n",
    "    DALI_REGISTER_OPERATOR(CustomDummy, ::other_ns::Dummy<::dali::CPUBackend>, ::dali::CPU);\n",
    "    \n",
    "    //简单的说明\n",
    "    DALI_SCHEMA(CustomDummy)\n",
    "        .DocStr(\"Make a copy of the input tensor\")\n",
    "        .NumInput(1)\n",
    "        .NumOutput(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPU版本的实现\n",
    "#! cat customdummy/dummy.cu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #include <cuda_runtime_api.h>\n",
    "    #include \"dummy.h\"\n",
    "\n",
    "    namespace other_ns {\n",
    "    \n",
    "    \n",
    "    //具体实现\n",
    "    template<>\n",
    "    void Dummy<::dali::GPUBackend>::RunImpl(::dali::DeviceWorkspace &ws) {\n",
    "      const auto &input = ws.Input<::dali::GPUBackend>(0);\n",
    "      auto &output = ws.Output<::dali::GPUBackend>(0);\n",
    "      CUDA_CALL(cudaMemcpyAsync(\n",
    "              output.raw_mutable_data(),\n",
    "              input.raw_data(),\n",
    "              input.nbytes(),\n",
    "              cudaMemcpyDeviceToDevice,\n",
    "              ws.stream()));\n",
    "    }\n",
    "\n",
    "    }  // namespace other_ns\n",
    "    \n",
    "    \n",
    "    //注册\n",
    "    DALI_REGISTER_OPERATOR(CustomDummy, ::other_ns::Dummy<::dali::GPUBackend>, ::dali::GPU);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用Cmake来编译，不是用pybild11\n",
    "#!cat customdummy/CMakeLists.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    cmake_minimum_required(VERSION 3.5)\n",
    "    project(custom_dummy_plugin)\n",
    "    find_package(CUDA 9.0 REQUIRED)\n",
    "\n",
    "    execute_process(\n",
    "            COMMAND python -c \"import nvidia.dali as dali; print(dali.sysconfig.get_lib_dir())\"\n",
    "            OUTPUT_VARIABLE DALI_LIB_DIR)\n",
    "    string(STRIP ${DALI_LIB_DIR} DALI_LIB_DIR)\n",
    "\n",
    "    execute_process(\n",
    "            COMMAND python -c \"import nvidia.dali as dali; print(\\\" \\\".join(dali.sysconfig.get_compile_flags()))\"\n",
    "            OUTPUT_VARIABLE DALI_COMPILE_FLAGS)\n",
    "    string(STRIP ${DALI_COMPILE_FLAGS} DALI_COMPILE_FLAGS)\n",
    "\n",
    "    set(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++14 ${DALI_COMPILE_FLAGS} \")\n",
    "    set(CUDA_NVCC_FLAGS \"${CUDA_NVCC_FLAGS} -std=c++14 ${DALI_COMPILE_FLAGS} \")\n",
    "    link_directories( \"${DALI_LIB_DIR}\" )\n",
    "\n",
    "    cuda_add_library(customdummy SHARED dummy.cc dummy.cu )\n",
    "    target_link_libraries(customdummy dali)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    !rm -rf customdummy/build\n",
    "    !mkdir -p customdummy/build\n",
    "    !cd customdummy/build && \\\n",
    "      cmake .. && \\\n",
    "      make\n",
    "      \n",
    "      \n",
    "     生成了! ls customdummy/build/*.so文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nvidia'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6145531198e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnvidia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdali\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugin_manager\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplugin_manager\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplugin_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./customdummy/build/libcustomdummy.so'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#调用\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_dummy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nvidia'"
     ]
    }
   ],
   "source": [
    "import nvidia.dali.plugin_manager as plugin_manager\n",
    "plugin_manager.load_library('./customdummy/build/libcustomdummy.so')\n",
    "#调用\n",
    "help(fn.custom_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTHON函数定义操作，因为python线程问题，只适合测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nvidia'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4a7d5883db98>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnvidia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdali\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplugin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpytorch\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdalitorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdlpack\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtorch_dlpack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nvidia'"
     ]
    }
   ],
   "source": [
    "import nvidia.dali.plugin.pytorch as dalitorch\n",
    "import torch\n",
    "import torch.utils.dlpack as torch_dlpack\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                              transforms.RandomPerspective(p=1.),\n",
    "                              transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def perspective(t):\n",
    "    return transform(t).transpose(2, 0).transpose(0, 1)\n",
    "\n",
    "\n",
    "\n",
    "def dlpack_manipulation(dlpacks):\n",
    "    tensors = [torch_dlpack.from_dlpack(dlpack) for dlpack in dlpacks]\n",
    "    output = [(tensor.to(torch.float32) / 255.).sqrt() for tensor in tensors]\n",
    "    output.reverse()\n",
    "    return [torch_dlpack.to_dlpack(tensor) for tensor in output]\n",
    "\n",
    "\n",
    "\n",
    "torch_function_pipe = Pipeline(batch_size=batch_size, \n",
    "                               num_threads=4, \n",
    "                               device_id=0,\n",
    "                               exec_async=False, \n",
    "                               exec_pipelined=False, \n",
    "                               seed=99)\n",
    "\n",
    "with torch_function_pipe:\n",
    "    \n",
    "    input, _ = fn.readers.file(file_root=image_dir, random_shuffle=True)\n",
    "    \n",
    "    im = fn.decoders.image(input, device='cpu', output_type=types.RGB)\n",
    "    \n",
    "    res = fn.resize(im, resize_x=300, resize_y=300)\n",
    "    \n",
    "    norm = fn.crop_mirror_normalize(res, std=255., mean=0.)\n",
    "    \n",
    "    perspective = dalitorch.fn.torch_python_function(norm, function=perspective)#用python的方法处理\n",
    "    \n",
    "    sqrt_color = fn.dl_tensor_python_function(res, function=dlpack_manipulation)\n",
    "    \n",
    "    torch_function_pipe.set_outputs(perspective, sqrt_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU这个才是核心\n",
    "   因为cupy和numpy是一样的,所以可以不用修改API，直接用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "\n",
    "#不能修改输入，而是只能够复制一份再修改   自定义操作\n",
    "def edit_images(image1, image2):\n",
    "    \n",
    "    assert image1.shape == image2.shape\n",
    "    h, w, c = image1.shape\n",
    "    y, x = cupy.ogrid[0:h, 0:w]\n",
    "    mask = (x - w / 2) ** 2 + (y - h / 2) ** 2 > h * w / 9\n",
    "    result1 = cupy.copy(image1)\n",
    "    result1[mask] = image2[mask]\n",
    "    result2 = cupy.copy(image2)\n",
    "    result2[mask] = image1[mask]\n",
    "    #cupy.cuda.get_current_stream().synchronize() \n",
    "    return result1, result2\n",
    "\n",
    "\n",
    "#或者写一个简单的kernel函数\n",
    "mix_channels_kernel = cupy.ElementwiseKernel(\n",
    "        'uint8 x, uint8 y',\n",
    "        'uint8 z',\n",
    "        'z = (i % 3) ? x : y',\n",
    "        'mix_channels'\n",
    "    )\n",
    "\n",
    "\n",
    "out1, out2 = fn.python_function(res1, res2, device='gpu', function=edit_images, num_outputs=2)\n",
    "\n",
    "\n",
    "out3       = fn.python_function(res1, res2, device='gpu', function=mix_channels_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a6f98c4a0314>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m python_function_pipe = Pipeline(batch_size=batch_size, num_threads=4, device_id=0,\n\u001b[0m\u001b[0;32m      6\u001b[0m                                 exec_async=False, exec_pipelined=False, seed=99)\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "#只要将‘gpu’指定出来就可以在GPU上使用\n",
    "image_dir = '../data/images'\n",
    "batch_size = 4\n",
    "\n",
    "#这里要求exec_async=False和exec_pipelined=False\n",
    "python_function_pipe = Pipeline(batch_size=batch_size, \n",
    "                                num_threads=4, \n",
    "                                device_id=0,\n",
    "                                exec_async=False, \n",
    "                                exec_pipelined=False, \n",
    "                                seed=99)\n",
    "\n",
    "with python_function_pipe:\n",
    "    input1, _ = fn.readers.file(file_root=image_dir, random_shuffle=True)\n",
    "    input2, _ = fn.readers.file(file_root=image_dir, random_shuffle=True)\n",
    "    im1, im2 = fn.decoders.image([input1, input2], device='mixed', output_type=types.RGB)\n",
    "    res1, res2 = fn.resize([im1, im2], device='gpu', resize_x=300, resize_y=300)\n",
    "    \n",
    "    out1, out2 = fn.python_function(res1, res2, device='gpu', function=edit_images, num_outputs=2)\n",
    "    \n",
    "    \n",
    "    out3 = fn.python_function(res1, res2, device='gpu', function=mix_channels_kernel)\n",
    "    \n",
    "    \n",
    "    python_function_pipe.set_outputs(out1, out2, out3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUPY使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单一元素运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8d377a8e933f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m squared_diff = cp.ElementwiseKernel(\n\u001b[0m\u001b[0;32m      2\u001b[0m   \u001b[1;34m'float32 x, float32 y'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#输入出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m    \u001b[1;34m'float32 z'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#输出\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m   \u001b[1;34m'z = (x - y) * (x - y)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#执行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   'squared_diff')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cp' is not defined"
     ]
    }
   ],
   "source": [
    "squared_diff = cp.ElementwiseKernel(\n",
    "  'T x, T y',#输入参数列表\n",
    "   'T z', #输出参数列表\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    z = (x - y) * (x - y);\n",
    "    \n",
    "    ''',#执行\n",
    "  'squared_diff'#name\n",
    ")\n",
    "squared_diff(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-90844ded0026>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#raw 的意思是就是用Y的原来类型，而不是每个元素执行，所以当用元素执行时，要给定他的索引\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m add_reverse = cp.ElementwiseKernel(\n\u001b[0m\u001b[0;32m      3\u001b[0m      \u001b[1;34m'T x, raw T y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'T z'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[1;34m'z = x + y[_ind.size() - i - 1]'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     'add_reverse')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cp' is not defined"
     ]
    }
   ],
   "source": [
    "#raw 的意思是就是用Y的原来类型，而不是每个元素执行，所以当用元素执行时，要给定他的索引\n",
    "add_reverse = cp.ElementwiseKernel(\n",
    "     'T x, raw T y', 'T z',\n",
    "     'z = x + y[_ind.size() - i - 1]',\n",
    "    'add_reverse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduction kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-85a44e07f96e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#看清他每一个位置的操作\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m l2norm_kernel = cp.ReductionKernel(\n\u001b[0m\u001b[0;32m      3\u001b[0m      \u001b[1;34m'T x'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# input params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[1;34m'T y'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# output params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m      \u001b[1;34m'x * x'\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cp' is not defined"
     ]
    }
   ],
   "source": [
    "#看清他每一个位置的操作\n",
    "l2norm_kernel = cp.ReductionKernel(\n",
    "     'T x',  # input params\n",
    "     'T y',  # output params\n",
    "     'x * x',  # map\n",
    "     'a + b',  # reduce\n",
    "     'y = sqrt(a)',  # post-reduction map\n",
    "     '0',  # identity value\n",
    "     'l2norm'  # kernel name\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6daa48c93a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m add_kernel = cp.RawKernel(\n\u001b[0m\u001b[0;32m      2\u001b[0m r'''\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mextern\u001b[0m \u001b[1;34m\"C\"\u001b[0m \u001b[0m__global__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m void my_add(const float* x1, const float* x2, float* y) {\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cp' is not defined"
     ]
    }
   ],
   "source": [
    "add_kernel = cp.RawKernel(\n",
    "r'''\n",
    "\n",
    "extern \"C\" __global__\n",
    "void my_add(const float* x1, const float* x2, float* y) {\n",
    "    int tid = blockDim.x * blockIdx.x + threadIdx.x;\n",
    "     y[tid] = x1[tid] + x2[tid];\n",
    " }\n",
    " \n",
    " ''',\n",
    "'my_add')\n",
    "x1 = cp.arange(25, dtype=cp.float32).reshape(5, 5)\n",
    "x2 = cp.arange(25, dtype=cp.float32).reshape(5, 5)\n",
    "y = cp.zeros((5, 5), dtype=cp.float32)\n",
    "add_kernel((5,), (5,), (x1, x2, y))  # grid, block and arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单机多卡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50,resnet18\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.cuda.is_available()\n",
    "device=torch.device('cuda')\n",
    "from torchvision import models\n",
    "from torch import nn\n",
    "import argparse\n",
    "import  torch.distributed as DDP\n",
    "#DALI\n",
    "\n",
    "import os.path\n",
    "from torchvision import models\n",
    "from nvidia.dali.pipeline import Pipeline\n",
    "import nvidia.dali.ops as ops\n",
    "import nvidia.dali.types as types\n",
    "import nvidia.dali.fn as fn\n",
    "#DALIClassificationIterator(pipelines, reader_name)  ==  DALIGenericIterator(pipelines, [\"data\", \"label\"], reader_name)\n",
    "from nvidia.dali.plugin.pytorch import DALIClassificationIterator, LastBatchPolicy#（这个是用于填充作用）\n",
    "from nvidia.dali.plugin.pytorch import DALIGenericIterator\n",
    "from random import shuffle\n",
    "\n",
    "txt_path='/kaggle/input/10-monkey-species/monkey_labels.txt'\n",
    "root='/kaggle/input/10-monkey-species/'\n",
    "training_data_path='/kaggle/input/10-monkey-species/training/training/'\n",
    "valid_data_path='/kaggle/input/10-monkey-species/validation/validation/'\n",
    "means=[110.508858,109.552668, 84.623747]\n",
    "stds=[67.212821,66.229520,66.544232]\n",
    "\n",
    "class ExternalInputIterator(object):\n",
    "    def __init__(self, batch_size, \n",
    "                 device_id,\n",
    "                 num_gpus,\n",
    "                ann_file=\"/kaggle/working/train.txt\",\n",
    "                img_prex='/kaggle/input/10-monkey-species/training/training/'):\n",
    "        self.ann_file =ann_file\n",
    "        self.batch_size = batch_size\n",
    "        self.img_prex=img_prex\n",
    "        #读取txt文本\n",
    "        with open(self.ann_file, 'r') as f:\n",
    "            self.files = [line.rstrip() for line in f if line is not '']\n",
    "        self.data_set_len = len(self.files)\n",
    "        self.files = self.files[self.data_set_len * device_id // num_gpus:self.data_set_len * (device_id + 1) //num_gpus]\n",
    "        self.n = len(self.files)\n",
    "    def __iter__(self):\n",
    "        self.i = 0\n",
    "        shuffle(self.files)\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        batch = []\n",
    "        labels = []\n",
    "        if self.i >= self.n:\n",
    "            raise StopIteration\n",
    "        #生成一个batch的数据\n",
    "        for _ in range(self.batch_size):\n",
    "            #处理字符串\n",
    "            jpeg_filename, label = self.files[self.i].split(' ')\n",
    "            # we can use numpy\n",
    "            batch.append(np.fromfile(self.img_prex+jpeg_filename, dtype = np.uint8)) \n",
    "            # or PyTorch's native tensors\n",
    "            labels.append(torch.tensor([int(label)], dtype = torch.uint8)) \n",
    "            self.i = (self.i + 1) % self.n\n",
    "            \n",
    "        return (batch, labels)#这里就说明了他是dataloader格式的结果\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_set_len\n",
    "\n",
    "#生成pipeline\n",
    "def ExternalSourcePipeline(batch_size, \n",
    "                           num_threads, \n",
    "                           device_id, \n",
    "                           external_data,\n",
    "                          is_training=True,\n",
    "                          dali_cpu=False):\n",
    "    pipe = Pipeline(batch_size, num_threads,device_id)\n",
    "\n",
    "    with pipe:\n",
    "        #用np.fromfile 读取成一列数据\n",
    "        jpegs, labels = fn.external_source(source=external_data, \n",
    "                                           num_outputs=2)#输出个数保证一致\n",
    "        \n",
    "        \n",
    "        #设置设备\n",
    "        dali_device = 'cpu' \n",
    "        decoder_device = 'cpu'\n",
    "        device_memory_padding = 211025920 \n",
    "        host_memory_padding = 140544512 \n",
    "        \n",
    "        \n",
    "        if is_training:\n",
    "            #增益方法\n",
    "            images = fn.decoders.image_random_crop(jpegs,\n",
    "                                                  device=decoder_device,\n",
    "                                                   output_type=types.RGB,\n",
    "                                                  device_memory_padding=device_memory_padding,\n",
    "                                                  host_memory_padding=host_memory_padding,\n",
    "                                                  random_aspect_ratio=[0.8, 1.25],\n",
    "                                                  random_area=[0.1, 1.0]\n",
    "                                                  ,num_attempts=100)\n",
    "            \n",
    "            \n",
    "            #images =augment(images)\n",
    "            images = fn.resize(images, resize_x=240, resize_y=240)\n",
    "            mirror = fn.random.coin_flip(probability=0.5)\n",
    "        else:\n",
    "            images = fn.decoders.image(jpegs,\n",
    "                                      device='mixed',\n",
    "                                      output_type=types.RGB)\n",
    "            images = fn.resize(images, resize_x=240, resize_y=240)\n",
    "            mirror = False\n",
    "        images = fn.crop_mirror_normalize(images.gpu(),\n",
    "                                          dtype=types.FLOAT,\n",
    "                                          output_layout=\"CHW\",\n",
    "                                          mean=[0.485 * 255,0.456 * 255,0.406 * 255],\n",
    "                                          std=[0.229 * 255,0.224 * 255,0.225 * 255],\n",
    "                                          mirror=mirror)\n",
    "        labels = labels.gpu()\n",
    "        pipe.set_outputs(images, labels)\n",
    "    return pipe\n",
    "\n",
    "\n",
    "def train(local_rank,train_eii,valids_eii,criterion,model,optimizer,exp_lr_scheduler):\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model.to(local_rank),device_ids=[local_rank])\n",
    "    train_pipe = ExternalSourcePipeline(batch_size=256, \n",
    "                                  num_threads=2,\n",
    "                                  device_id = local_rank,\n",
    "                                  external_data = train_eii,\n",
    "                                   dali_cpu=False)\n",
    "    train_pipe.build()\n",
    "    train_loader= DALIGenericIterator(train_pipe,\n",
    "                              [\"images\",\"labels\"],\n",
    "                               size=len(train_eii),\n",
    "                              auto_reset=True,\n",
    "                              last_batch_policy=LastBatchPolicy.PARTIAL)#其他任务要调用这个\n",
    "    valid_pipe = ExternalSourcePipeline(batch_size=64, \n",
    "                                  num_threads=2, device_id = local_rank,\n",
    "                                  external_data = valids_eii,is_training=False,dali_cpu=False)\n",
    "    valid_pipe.build()\n",
    "    valid_loader= DALIGenericIterator(valid_pipe,\n",
    "                              [\"images\",\"labels\"],\n",
    "                               size=len(valids_eii),\n",
    "                              last_batch_policy=LastBatchPolicy.PARTIAL)#其他任务要调用这个      \n",
    "    epochs= 50\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss= 0.0\n",
    "        epoch_count = 0\n",
    "        model.train()\n",
    "        print(f'Epoch {epoch}/{epochs}')\n",
    "        print('----------------------------')\n",
    "        start_time = time.time()\n",
    "   \n",
    "        for i,data in enumerate(train_loader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            img = data[0][\"images\"].cuda(local_rank)#注意标签\n",
    "            label_train = data[0][\"labels\"].squeeze(-1).cuda(local_rank).long()\n",
    "            prediction = model(img)\n",
    "            _ , correct = torch.max(prediction,dim=1)\n",
    "            loss = criterion (prediction,label_train)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_count +=  (correct==label_train).sum().item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            exp_lr_scheduler.step()\n",
    "            one_epoch_time = time.time()-start_time\n",
    "        print (f'one_epoch_time :{one_epoch_time:.4f},lr : {optimizer.param_groups[0][\"lr\"]},train Loss: {epoch_loss:.4f} Acc:{epoch_count/len(train_loader)/256*100:.4f} ')\n",
    "        if (epoch+1) % 3 == 0:\n",
    "            model.eval()\n",
    "            eval_loss=0.0\n",
    "            eval_count=0.0\n",
    "\n",
    "            for data in valid_loader:\n",
    "\n",
    "                image = data[0][\"images\"].cuda(local_rank)\n",
    "                label = data[0][\"labels\"].squeeze(-1).cuda(local_rank).long()\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    pred=model(image)\n",
    "\n",
    "                    loss = criterion(pred,label)\n",
    "                    _ , count = torch.max(pred,dim=1)\n",
    "                    eval_count += (count==label).sum().item()\n",
    "                    eval_loss += loss.item()\n",
    "            print (f'local_rank is {local_rank},valid Loss: {eval_loss:.4f} Acc:{eval_count /len(valid_loader)/64*100:.4f}')\n",
    "\n",
    "            model.train()\n",
    "            \n",
    "        train_loader.reset()\n",
    "        valid_loader.reset()\n",
    "        \n",
    "        if local_rank==0 and epoch%10==0:\n",
    "            torch.save(model.module.state_dict(),'test.pt')\n",
    "def main(resume=True):\n",
    "    parser = argparse.ArgumentParser(description='Train a model')\n",
    "    parser.add_argument('--local_rank',type=int)\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    n_gpu=2\n",
    "    DDP.init_process_group(backend='nccl',world_size=n_gpu,rank = args.local_rank)\n",
    "    model =resnet18(pretrained=True) \n",
    "    ins = model.fc.in_features\n",
    "    model.fc =nn.Linear(ins,10)\n",
    "    \n",
    "    if resume:\n",
    "        model.load_state_dict(torch.load('test.pt'))\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(),lr=0.01,weight_decay=1e-4, amsgrad=False)\n",
    "    exp_lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10)\n",
    "    \n",
    "    #实例化训练数据的来源，生成器\n",
    "    train_eii = ExternalInputIterator(256, 0, 1)\n",
    "    valids_eii = ExternalInputIterator(64, 0, 1, \n",
    "                    ann_file=\"/kaggle/working/valid.txt\",\n",
    "                    img_prex='/kaggle/input/10-monkey-species/validation/validation/')\n",
    "\n",
    "    train(args.local_rank, train_eii,valids_eii,criterion,model,optimizer,exp_lr_scheduler)\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
