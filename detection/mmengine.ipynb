{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5ff83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U openmim\n",
    "!mim install mmengine\n",
    "#必须满编\n",
    "!mim install mmcv-full\n",
    "!git clone https://github.com/open-mmlab/mmdetection.git\n",
    "%cd mmdetection\n",
    "!pip install -v -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23d53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mmcv\n",
    "from mmcv.transforms import Compose\n",
    "from mmengine.utils import track_iter_progress\n",
    "from mmdet.registry import VISUALIZERS\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules# 如果无法build，要用这个函数\n",
    "config_file = 'configs/rtmdet/rtmdet_l_8xb32-300e_coco.py'\n",
    "checkpoint_file = 'checkpoints/rtmdet_l_8xb32-300e_coco_20220719_112030-5a0be7c4.pth'\n",
    "\n",
    "# 根据配置文件和 checkpoint 文件构建模型\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0')\n",
    "\n",
    "# 初始化可视化工具\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "# 从 checkpoint 中加载 Dataset_meta，并将其传递给模型的 init_detector\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# 测试单张图片并展示结果\n",
    "img = 'test.jpg'  # 或者 img = mmcv.imread(img)，这样图片仅会被读一次\n",
    "result = inference_detector(model, img)\n",
    "\n",
    "# 显示结果\n",
    "img = mmcv.imread(img)\n",
    "img = mmcv.imconvert(img, 'bgr', 'rgb')\n",
    "\n",
    "\n",
    "\n",
    "visualizer.add_datasample(\n",
    "    'result',\n",
    "    img,\n",
    "    data_sample=result,\n",
    "    draw_gt=False,\n",
    "    wait_time=0,\n",
    ")\n",
    "visualizer.show()\n",
    "\n",
    "# 测试视频并展示结果\n",
    "# 构建测试 pipeline\n",
    "model.cfg.test_dataloader.dataset.pipeline[0].type = 'LoadImageFromNDArray'\n",
    "test_pipeline = Compose(model.cfg.test_dataloader.dataset.pipeline)\n",
    "\n",
    "# 可视化工具在第33行和35行已经初完成了初始化，如果直接在一个 jupyter nodebook 中运行这个 demo，\n",
    "# 这里则不需要再创建一个可视化工具了。\n",
    "# 初始化可视化工具\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "# 从 checkpoint 中加载 Dataset_meta，并将其传递给模型的 init_detector\n",
    "visualizer.dataset_meta = model.dataset_meta\n",
    "\n",
    "# 显示间隔 (ms), 0 表示暂停\n",
    "wait_time = 1\n",
    "\n",
    "video = mmcv.VideoReader('video.mp4')\n",
    "\n",
    "cv2.namedWindow('video', 0)\n",
    "\n",
    "for frame in track_iter_progress(video_reader):\n",
    "    result = inference_detector(model, frame, test_pipeline=test_pipeline)\n",
    "    visualizer.add_datasample(\n",
    "        name='video',\n",
    "        image=frame,\n",
    "        data_sample=result,\n",
    "        draw_gt=False,\n",
    "        show=False)\n",
    "    frame = visualizer.get_image()\n",
    "    mmcv.imshow(frame, 'video', wait_time)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3145907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#命令行 单张图\n",
    "python demo/image_demo.py \\\n",
    "    ${IMAGE_FILE} \\\n",
    "    ${CONFIG_FILE} \\\n",
    "    [--weights ${WEIGHTS}] \\\n",
    "    [--device ${GPU_ID}] \\\n",
    "    [--pred-score-thr ${SCORE_THR}]\n",
    "#摄像头\n",
    "python demo/webcam_demo.py \\\n",
    "    ${CONFIG_FILE} \\\n",
    "    ${CHECKPOINT_FILE} \\\n",
    "    [--device ${GPU_ID}] \\\n",
    "    [--camera-id ${CAMERA-ID}] \\\n",
    "    [--score-thr ${SCORE_THR}]\n",
    "\n",
    "#视频\n",
    "python demo/video_demo.py \\\n",
    "    ${VIDEO_FILE} \\\n",
    "    ${CONFIG_FILE} \\\n",
    "    ${CHECKPOINT_FILE} \\\n",
    "    [--device ${GPU_ID}] \\\n",
    "    [--score-thr ${SCORE_THR}] \\\n",
    "    [--out ${OUT_FILE}] \\\n",
    "    [--show] \\\n",
    "    [--wait-time ${WAIT_TIME}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c1aba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c2c629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化数据集\n",
    "from mmengine.visualization import Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "test=train[18]\n",
    "img = test['img'].data.permute(1,2,0).numpy()\n",
    "img = img[..., [2, 1, 0]] \n",
    "vis  = Visualizer(image = img, save_dir='temp_dir')\n",
    "bboxes = test['gt_bboxes'].data#/test['img_metas'].data['scale_factor']\n",
    "vis.dataset_meta =train.metainfo\n",
    "vis.draw_bboxes(bboxes,edge_colors='r')\n",
    "vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13320116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aa0927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89532cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82596ac",
   "metadata": {},
   "source": [
    "# 后端模型的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8988c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdeploy.apis.utils import build_task_processor\n",
    "from mmdeploy.utils import get_input_shape, load_config\n",
    "import torch\n",
    "\n",
    "deploy_cfg = '../mmdeploy/configs/mmdet/detection/detection_onnxruntime_dynamic.py'\n",
    "model_cfg = 'configs/faster_rcnn/faster-rcnn_r50_fpn_1x_coco.py'\n",
    "device = 'cpu'\n",
    "backend_model = ['mmdeploy_models/mmdet/onnx/end2end.onnx']\n",
    "image = 'demo/demo.jpg'\n",
    "\n",
    "# read deploy_cfg and model_cfg\n",
    "deploy_cfg, model_cfg = load_config(deploy_cfg, model_cfg)\n",
    "\n",
    "# build task and backend model\n",
    "task_processor = build_task_processor(model_cfg, deploy_cfg, device)\n",
    "model = task_processor.build_backend_model(backend_model)\n",
    "\n",
    "# process input image\n",
    "input_shape = get_input_shape(deploy_cfg)\n",
    "model_inputs, _ = task_processor.create_input(image, input_shape)\n",
    "\n",
    "# do model inference\n",
    "with torch.no_grad():\n",
    "    result = model.test_step(model_inputs)\n",
    "\n",
    "# visualize results\n",
    "task_processor.visualize(\n",
    "    image=image,\n",
    "    model=model,\n",
    "    result=result[0],\n",
    "    window_name='visualize',\n",
    "    output_file='output_detection.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55e863",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3e6e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887f049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879f8e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec31da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2e520b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de14b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
